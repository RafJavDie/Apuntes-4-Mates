	\documentclass[twoside]{article}
\usepackage{../../estilo-ejercicios}

%--------------------------------------------------------
\begin{document}

\title{Ejercicios de From Calculus to Cohomology, Capítulo 9}
\author{Javier Aguilar Martín}
\maketitle

\begin{ejercicio}{9.1}
Sea $M\subseteq\R^l$ una subvariedad diferenciable y supongamos que los puntos $p\in\R^l$ y $p_0\in M$ son tales que $||p-p_0||\leq ||p-q||$ para todo $q\in M$. Probar que $p-p_0\in T_{p_0}M^{\perp}$.
\end{ejercicio}
\begin{solucion}
Consideramos el segmento que va de $p$ a $p_0$, que debe atravesar el entorno tubular $V$ de $M$. Llamamos $\hat{p}$ a un punto de intersección del segmento con $V$. Como $p_0$,$\hat{p}$ y $p$ están alineados, basta probar que $r(\hat{p})=p_0$. Tenemos que $\hat{p}\in V\cap \gene{p_0+(p-p_0)}$ (de modo que $\hat{p}$ esté en la componente conexa que contiene a $p_0$). Además, $p-p_0=p-\hat{p}+\hat{p}-p_0$, que tomando norma se traduce en $|p-q|\leq |p-p_0|=|p-\hat{p}+\hat{p}-p_0|=|p-\hat{p}|+|\hat{p}-p_0|$ y $|\hat{p}-p_0|\leq |\hat{p}-q|$ para todo $q\in M$. La última desigualdad nos da que $p_0=r(\hat{p})$, por lo que $p_0-\hat{p}=r(\hat{p})-\hat{p}\in T_pM^{\perp}$, siendo $p_0-\hat{p}$ paralelo a $p-p_0$.

%https://math.stackexchange.com/questions/1492497/projection-theorem-understanding-two-parts-of-the-proof


\end{solucion}
\newpage


\begin{ejercicio}{9.9}
En el espacio vectorial $M=M_n(\R)$ de matrices reales $n\times n$ tenemos el subespacio de matrices simétricas $S_n$. Definimos la aplicación diferenciable $\varphi:M\to S_n$ como 
\[
\varphi(A)=A^tA.
\]
Nótese que $\varphi^{-1}(I)$ es el espacio de matrices ortogonales $O_n$. Probar que para $A,B\in M$ tenemos
\[
D_A\varphi(B)=B^tA+A^tB.
\]
(Pista: usar la curva $A+sB$)
Aplicar el ejercicio 9.6 para probar que $O_n$ es una subvariedad diferenciable de $M$.
\end{ejercicio}
\begin{solucion}
Tomamos la curva $\gamma(s)=A+sB$ tal que $\gamma'(0)=B$. Entonces, 
\[
D_A\varphi(B)=D_A\varphi(\gamma'(0))=(\varphi\circ\gamma)'(0)=A^tB+B^tA.
\]

Para la segunda parte tenemos que probar que $D_A\varphi$ es sobreyectiva para toda matriz ortogonal $A$. Es decir, dada $\gamma:[0,1]\to S_n$ con $\gamma'(0)\in S_n$, tenemos que encontrar $B\in M$ tal que $\gamma'(0)=B^tA+A^tB$. Para ello hacemos la siguiente descomposición:
\[
\gamma'(0)=\frac{(\gamma'(0)A^t)}{2}A+A^t\frac{(A\gamma'(0))}{2}
\]
con lo que $B=\frac{A\gamma'(0)}{2}$.
Esto es suficiente pues por ser $O_n$ subespacio vectorial de $M_n(\R)$, tiene estructura de subvariedad diferenciable. De hecho tiene $\dim(S_n)=\frac{(n+1)n}{2}$.
\end{solucion}
\newpage

\begin{ejercicio}{9.10}
Un \emph{grupo de Lie} $G$ es una variedad diferenciable, que es también un grupo, tal que el producto y tomar inverso son diferenciables. Demostrar que $O_n$ es un grupo de Lie. (Aplicar \ref{ejer:9.9})
\end{ejercicio}
\begin{solucion}
$O_n$ hereda la estructura diferenciable de $M_n(\R)$, que es equivalente a la de $\R^{n\times n}$. Es claro que el producto de matrices es diferenciable, luego en $O_n$ lo es. En el caso de la inversa, como en el caso de $O_n$ es igual a trasponer, que no es más que una reordenación de las coordenadas es también claro que se trata de una aplicación diferenciable.
\end{solucion}
\newpage

\begin{ejercicio}{9.11}
Sea $\varphi:M\to N$ una aplicación diferenciable entre variedades diferenciables. Probar que $\varphi^*:\Omega^*(N)\to\Omega^*(M)$ es un morfismo de complejos de cadenas.
\end{ejercicio}
\begin{solucion}
Tenemos que probar que el siguiente diagrama es conmutativo 
\[
\begin{tikzcd}
\Omega^k(N)\arrow[r,"d^k"]\arrow[d,"\varphi^*"] & \Omega^{k+1}(N)\arrow[d,"\varphi^*"]\\
\Omega^k(M)\arrow[r, "d^k"] & \Omega^{k+1}(M)
\end{tikzcd}
\]
para todo $k$. Sea $w\in\Omega^k(N)$. Elegimos $p\in M,q=\varphi(p)\in N$ y parametrizaciones locales $g:W\to M$ y $h:V\to N$. Tenemos por definición
\[
d_qw=Alt^{k+1}((D_yh)^{-1})d_y(h^*(w))=Alt^{k+1}(D_qh^{-1})d_y(h^*(w))
\]
donde $y$ cumple $h(y)=q=\varphi(p)$, así que
\[
\varphi^*(d_qw)_p=Alt^{k+1}(D_p\varphi)\circ Alt^{k+1}(D_qh^{-1})(d_yh^*(w))=
\]
\[
Alt^{k+1}(D_qh^{-1}D_p\varphi)(d_yh^*(w))=Alt^{k+1}(D_ph^{-1}\varphi)(d_y(h^*(w)))=
\]
%\[
%Alt^{k+1}(D_ph^{-1}\varphi)(d_yAlt^k(D_yh)(w_{h(y)})).
%\]
%Ahora, por la conmutatividad de $d$ con $\Omega^k(h)$ a nivel de complejo de cocadenas de abiertos euclídeos, esto es igual a 
%\[
%Alt^{k+1}(D_ph^{-1}\varphi)Alt^{k+1}(D_yh)(d_q w_{\varphi(p)})=Alt^{k+1}(D_p\varphi)(d_yw_{\varphi(p)}).
%\]
% 
Por otro lado, 
%\[
%\varphi^*(w)_p=Alt^k(D_p\varphi)(w_{\varphi(p)}),
%\]
%así que 
eligiendo $x$ con  $g(x)=p$ tenemos
\[
d_p\varphi^*(w)=Alt^{k+1}((D_xg)^{-1})d_x(g^*(\varphi^*(w)))=
\]
%\[
%Alt^{k+1}(D_xg^{-1})d_x(Alt^k(D_xg)\circ Alt^k(D_p\varphi)(w_{\varphi(p)}))=
%\]
%\[
%Alt^{k+1}(D_xg^{-1})d_x(Alt^k(D_x\varphi g)(w_{\varphi(p)})=Alt^{k+1}(D_p\varphi)(d_x w_{\varphi(p)})
%\]

SUPONGO QUE NO ME QUEDA MÁS REMEDIO QUE EVALUAR EN VECTORES
\end{solucion}

\newpage

\begin{ejercicio}{9.12}
El producto escalar usual en $\R^n$ induce un producto escalar en $Alt^n(\R^n)$ (ver ejercicio 2.5). Probar que $w\in Alt^n(\R^n)$ es un vector unitario si y solo si $w(v_1,\dots, v_n)=\pm 1$ para toda base ortonormal $\{v_1,\dots, v_n\}$ de $\R^n$.
\end{ejercicio}
\begin{solucion}
Dada $w\in Alt^n(\R^n)$ tenemos que $w=\lambda \varepsilon_1\land\dots\varepsilon_n=\lambda\varepsilon_I$ con $\lambda\in\R$. Entonces $\gene{w,w}=\lambda^2\det(\gene{\varepsilon_i,\varepsilon_j})=\lambda^2\det(\gene{i^{-1}(\varepsilon_i),i^{-1}(\varepsilon_j)})=\lambda^2$. La última igualdad se tiene porque $i$ lleva bases ortonormales en bases ortonormales y estamos tomando la dual de la base estándar. Por otra parte, $w(v_1,\dots, v_n)=\lambda\det(\varepsilon_i(v_j))=\pm\lambda$. Así que $\gene{w,w}=1\Leftrightarrow \lambda=1\Leftrightarrow w(v_1,\dots, v_n)=\pm 1$.
\end{solucion}

\newpage

\begin{ejercicio}{9.13}
Probar que la botella de Klein no es orientable.
\end{ejercicio}
\begin{solucion}
Por reducción al absurdo, supongamos que $K^2$ es orientable, entonces existe $\sigma\in\Omega^2(K^2)$ que no se anula en ningún punto $x\in K^2$, es decir, es una forma de orientación. Denotamos $\hat{\pi}=p\circ\pi$. Entonces $\hat{\pi}^*(\sigma)\in\Omega^2(\R^2)$ es forma de orientación porque $\hat{\pi}$ es isomorfismo por composición de isomorfismos. Así que $\hat{\pi}^*=f dx_1\land dx_2$ con $f\in C^{\infty}(\R^2;\R)$. Sin pérdida de generalidad supongamos que $f(x,y)>0$ para todo $(x,y)\in\R^2$. Pero por conmutatividad, $\hat{A}^*\hat{\pi}^*=\hat{A}^*(fdx_1\land dx_2)=f(\hat{A})\hat{A}^*(dx_1)\land\hat{A}^*(dx_2)=f\circ\hat{A} d\hat{A}_1\land d\hat{A}_2=(f\circ\hat{A}) dx_1\land (-dx_2)=-f\circ\hat{A} dx_1\land dx_2$, que es constantemente negativo. Contradicción. 
\end{solucion}
\newpage

\begin{ejercicio}{9.14}
Sea $M$ una variedad Riemanniana de dimensión $n$ y $f\in C^{\infty}(M;\R)$. Se define el campo vectorial gradiente $grad f$ en $M$ exigiendo que $grad_pf\in T_pM$ verifique
\[
\gene{grad_pf,v}_p=D_pf(v)
\]
para todo $v\in T_pM$. Probar que para una parametrización local $h:W\to M$, se tiene
\[
grad_{h(x)}f=\sum_{j=1}^n a_j(x)\left(\parcial{}{x_i}\right)_{h(x)}
\]
donde $a_j\in C^{\infty}(W;\R)$, $1\leq j\leq n$ están determinadas por el sistema de ecuaciones lineales 
\[
\sum_{i=1}^n g_{ij}(x)a_j(x)=\parcial{f}{x_i}(x)\quad (1\leq i\leq n).
\]
Probar que la aplicación $grad f:M\to TM$ es diferenciable.

Sea $p\in M$ con $grad_p f\neq 0$. Sea $c=f(p)$. Probar que $f^{-1}(c)$ en un entorno de $p$ es una $(n-1)$-subvariedad diferenciable, y que $grad_pf$ es un vector normal a $f^{-1}(c)$ en $p$. 
\end{ejercicio}
\begin{solucion}
Dada la parametrización $h:W\to M$, tomamos como baste de $T_h(x)M$ la base habitual de las derivadas parciales en $h(x)$. Recordemos que
\[
\left(\parcial{}{x_i}\right)_{h(x)}=\phi_{h^{-1}}(e_i)=D_xh(e_i)
\]
donde $\{e_i,\dots, e_i\}$ la base de $\R^n$. Entonces
\[
\gene{grad_{h(x)}f,\left(\parcial{}{x_j}\right)_{h(x)}}=D_{h(x)}f\left(\parcial{}{x_j}\right)_{h(x)}=D_{h(x)}f(D_xh(e_j))=D_x(f\circ h)(e_j)=\left(\parcial{f\circ h}{x_j}\right)_x
\]
Y por otro lado 
\[
\gene{grad_{h(x)}f,\left(\parcial{}{x_j}\right)_{h(x)}}=\gene{\sum_{i=1}^na_i(x)\left(\parcial{}{x_i}\right),\left(\parcial{}{x_j}\right)_{h(x)}}=\sum_{i=1}^na_i(x)\gene{\left(\parcial{}{x_i}\right), \left(\parcial{}{x_j}\right)}=\sum_{i=1}^n g_{ij}(x)a_i(x)
\]

Veamos que $grad(f):M\to TM$ es diferenciable. Damos un atlas diferenciable sobre $TM=\{(p,v)\mid p\in M, v\in T_pM\}\subseteq M\times
\R^n$. Para cada $p\in M$, $g:W\to M$ parametrización alrededor de $p\in M$, 
\begin{align*}
W\times\R^n\longrightarrow \pi^{-1}(W)\\
(x,v)\longmapsto (g(x), D_xg(v))
\end{align*}
es una parametrización de $TM$. 

Así, dado $p\in M$, $grad(f):M\to TM$ está definido por $p\mapsto (p,grad_p(f))$. Dada una carta $(U,h)$ alrededor de $p$, entonces $(U\times\R^n, h\times D_ph)$ es una carta alrededor de $(p,grad_p(f))$. La composición nos da $(h(p), (a_1(x),\dots, a_n(x))$ que es diferenciable. 

Para la última parte, comprobamos que en un entorno de $p\in f^{-1}(c)$ tenemos una subvariedad diferenciable de dimensión $n-1$ con $grad_p(f)$ normal a $f^{-1}(c)$ en $p$. Sea $g:W\to M$ una parametrización alrededor de $p\in M$.  Entonces tenemos la composición $W\xrightarrow{g}M\xrightarrow{f}\R$, con $p=g(x_0)$. Tenemos que
\[
0\neq grad_p(f)=\sum_{j=1}^na_i(x_0)\left(\parcial{}{x_j}\right)_{g(x_0)}
\]
por lo que existe $V\subseteq W$ entorno de $x_0$ de modoq ue $grad_{g(x)}f\neq 0$ para todo $x\in V$. Por tanto existe $v\in T_pM$ de modo que $\gene{grad_{g(x)}f,v}=D_pf(v)\neq 0$, así que dado $q\in g(V)$, $D_qf:T_qM\to T_{f(q)}\R=\R$ es no nulo, así que es sobreyectivo. Aplicando 9.5 y 9.6, $V\cap f^{-1}(c)$ es subvariedad diferenciable de $V$ y por tanto de $M$, de dimensión $\dim(g(V))-\dim(\R)=n-1$. Veamos ahora que $grad_pf\in T_pf^{-1}(c)^{\perp}$. Sea $[\alpha]\in T_pf^{-1}(c)$, comprobemso que $\gene{grad_pf,[\alpha]}_p=0$. Este producto es $D_pf([\alpha])=(\alpha\circ f)'(0)$. Como $\alpha$ es una curva en $f^{-1}(c)$, $\alpha\circ f$ es constantemente $c$, por lo que la derivada es 0. 
. 
\end{solucion}
\newpage

\begin{ejercicio}{9.15}
Sea $M$ una variedad diferenciable $n$-dimensional y denotemos por $\widetilde{M}$ el conjunto de los pares $(p, o_p)$, donde $p\in M$ y $o_p$ es una de las dos orientaciones de $T_pM$. La proyección $\pi:\widetilde{M}\to M$ envía $(p,o_p)$ a $p$. 

Para un abierto orientado $W\subseteq M$ con forma de orientación $w\in\Omega^n(W)$ denotamos $\widetilde{W}\subseteq\widetilde{M}$ al conjunto de pares $(p,o_p)$, donde $p\in W$ y $o_p$ es la orientación de $T_pM$ determinada por $w_p\in Alt^n T_pM$.

Probar que $\widetilde{M}$ tiene una topología tal que $\widetilde{W}$ es abierto y $\pi$ es un homeomorfismo entre $\widetilde{W}$ y $W$ para todo abierto orientado $W\subseteq M$. Probar que $\widetilde{M}$ tiene una orientación canónica. El par consistente en $\widetilde{M}$ y $\pi$ se llama \emph{oriented double covering} (doble recubridor orientado) de $M$.
\end{ejercicio}
\begin{solucion}
Para cada abierto orientado $W\subseteq M$ con forma de orientación $w\in\Omega^n(W)$ definimos los conjuntos $W_+=\{(p,o_p)\in\widetilde{M}\mid p\in W, o_p\in [w]\}$ y $W_-\{(p,o_p)\in\widetilde{M}\mid p\in W, o_p\notin[w]\}$. Dotamos a $\widetilde{M}$ de la topología que tiene como base el de abiertos la familia $\{W_+,W_-\}_{W\subseteq M}$.

%es trivial COMPROBAR QUE ES BASE, ES DECIR QUE $\widetilde{M}\cap\widetilde{N}$ CUANDO ES NO VACÍO TIENE UN ENTORNO DE LA MISMA FORMA DENTRO

 Con la notación del enunciado, $\widetilde{W}=W_+$ y es evidente que $\pi:W_+\to W$ es homeomorfismo con esta topología.

Construimos un atlas sobre $\widetilde{M}$ a partir del atlas $\{(U,\varphi)\}$ de $M$. Para ello consideramos la familia $\{(U_\pm, \varphi_\pm)\}$ con $\varphi_\pm:=\varphi\circ\pi$. Es claro que los abiertos recubren $\widetilde{M}$ y por la observación anterior, $\varphi_\pm$ es un homeomorfismo entre $U_\pm$ y $\varphi(U)$. Además, dadas dos cartas $(U_\pm,\varphi_\pm)$ y $(V_\pm,\psi_\pm)$, se tiene que la aplicación
\[
\psi_\pm\circ \varphi_\pm^{-1}=\psi\circ\pi\circ\pi^{-1}\circ\varphi^{-1}=\psi\circ\varphi\in C^{\infty}
\]
pues $\pi$ se está restringiendo a un dominio donde es homeomorfismo.

Se puede orientar $\widetilde{M}$ con la forma de orientación $w\in\Omega^n(\widetilde{M})$ que en cada punto $(p,o_p)$ vale $o_p$. 


\end{solucion}
\newpage

\begin{ejercicio}{9.16}
Sea $M$ una variedad diferenciable conexa. Probar que $\widetilde{M}$ consiste en a lo sumo dos componentes conexas, y que $M$ es orientable si y solo si $\widetilde{M}$ es conexa.
\end{ejercicio}
\begin{solucion}
Si $M$ es orientable, entonces podemos considerar $\widetilde{M}_+$ y $\widetilde{M}_-$, que son abiertos disjuntos que recubren $\widetilde{M}$, de modo que $\widetilde{M}$ tiene dos componentes conexas.


Supongamos que $M$ es no orientable y sea $W\subseteq\widetilde{M}$ una componente conexa. La restricción $\pi|_W: W\to M$ sigue siendo un recubridor diferenciable. Efectivamente, para cada abierto $U\subseteq M$, cada componente conexa de $\pi^{-1}(U)$ está en una única componente conexa de $\widetilde{M}$, por lo que podemos quedarnos con las preimágenes que estén en $W$. Así que todas las fibras tienen el mismo cardinal. Esto quiere decir que  las fibras en $W$ tienen cardinalidad 1 o 2. Si tuvieran cardinalidad 1, entonces $\pi|_W$ sería un difeomorfismo y su inversa induciría una orientación en $M$. De esta forma, la cardinalidad de las fibras es 2 y eso implica que necesariamente $W=\widetilde{M}$, con lo que se tienen la conexión.

SOLUCIÓN DE CLASE

Sea $F:\widetilde{M}\to S^0=\{1,-1\}$ dotando a $S^0$ tiene la topología discreta. Fijada una orientación de $\R^n$, la podemos comparar con la orientación $o_p$ para todo $(p,o_p)\in\widetilde{M}$ , pues $D_{(p,o_p)}:T_{(p,o_p)}\widetilde{M}\to T_pM$ y $D_p\varphi:T_pM\to T_{\varphi(p)}\R^n=\R^n$ son isomorfismos. Así que $F(p,o_p)=1$ si $o_p$ es la orientación de $\R^n$ y $-1$ en caso contrario. Entonces $F^{-1}(\pm 1)$ son abiertos por definición de la topología de $\widetilde{M}$, por lo que $F$ es continua. 

Veamos que $\widetilde{M}$ tiene a lo más 2 componentes conexas. Supongamos que tiene más, entonces sin pérdida de generalidad al menos dos componentes $C_1,C_2$ verifican $F(C_1)=F(C_2)=1$.  Sean $(p,o_p)\in \hat{U}_{\alpha,i}\subseteq C_1$ y $(q,o_q)\in\hat{U}_{\beta,j}\subseteq C_2$. Como $M$ es conexo, tenemos una cadena $U_\alpha=U_{\alpha_1},\dots, U_{\alpha_m}=U_{\beta}$ de modo que las intersecciones no son vacías. Entonces podemos levantar esta cadena a $\widetilde{M}$ mediante $\pi^{-1}$ eligiendo en cada caso el abierto preimagen adecuado. Entonces conseguiríamos una cadena uniendo $(p,o_p)$ y $(q,o_q)$ con lo que estarían en la misma componente conexa.

Si $\widetilde{M}$ no es conexo, $\widetilde{M}=C_1\sqcup C_2$, que es orientable, luego los $C_i$ son orientables, de modo que $\pi(C_1)$ es orientable por la orientación inducida. 

Si $M$ es orientable, elegimos una forma de orientación $\sigma\in\Omega^n(M)$. Definimos $s:M\to\widetilde{M}$ como $x\mapsto s(x)=(x,[\sigma_x])$ y $t$ análogamente como $t(x)=(x,-[\sigma_x])$. Entonces $F\circ s=1$ y $F\circ t=-1$, por lo que $s(M)\neq t(M)$ son componentes distintas.
 
\end{solucion}
\newpage

\begin{ejercicio}{9.17}
Sea $V\subseteq\R^{n+k}$ un entorno tubular de una subvariedad diferenciable $M\subseteq\R^{n+k}$ de dimensión $n$ con la proyección asociada $r:V\to M$. Se define la aplicación diferenciable $f:V-M\to\R$ mediante
\[
f(x)=||x-r(x)||=\min_{y\in M}||x-y||.
\]
Probar que $f$ es una solución a la ecuación diferencial 
\[
\sum_{j=1}^{n+k}\left(\parcial{f}{x_j}\right)^2=1.
\]
Supongamos que $k=1$ y que $M$ está orientada por una aplicación de Gauss $Y$. Podemos definir la distancia signada de $M$, $\varphi:V\to R$ requiriendo
\[
\varphi(x)Y(r(x))=x-r(x)\quad (x\in V).
\]
Probar que $\varphi$ es una solución de la ecuación 
\[
\sum_{j=1}^{n+1}\left(\parcial{\varphi}{x_j}\right)^2=1.
\]
\end{ejercicio}
\begin{solucion}
Recordemos del ejercicio \ref{ejer:9.14} que para $x\in V-M$
\[
\gene{grad_xf, grad_xf}_x=\gene{\sum_{i=1}^na_i(x)\left(\parcial{}{x_i}\right)_x,\sum_{i=1}^na_i(x)\left(\parcial{}{x_i}\right)_x}=\sum_{i=1}^n\sum_{j=1}a_i(x)a_j(x)\gene{\left(\parcial{}{x_i}\right)_x, \left(\parcial{}{x_j}\right)_x}=\sum_{i=1}^na_i(x)^2
\]
porque podemos elegir una base para que sean ortogonales. Así que 
\[
\gene{grad_xf,\left(\parcial{}{x_i}\right)_x}_x=a_i(x) 
\]
y al mismo tiempo es igual a $D_xf\left(\left(\parcial{}{x_i}\right)_x\right)=\left(\parcial{f}{x_i}\right)(x)$.

Dado $x\in V-M$ y $\varepsilon=f(x)$, vemos que $x\in S_{\varepsilon}=f^{-1}(f(x))\subseteq V$ es subvariedad de $\R^{n+k}$ de codimensión 1. Tomamos $(W,s,i)$ con $W\supseteq S_{\varepsilon}$ entorno tubular de $S_{\varepsilon}$ y sea $l=[x,r(x)]$. Tomamos $y\in l\cap V\cap W$ en la componente conexa de $x$ en $l\cap V\cap W$. Se verifica $|y-s(y)|=\min\{|y-z|, z\in S_{\varepsilon}\}\leq |y-x|$. Entonces $|x-r(x)|=|x-y|+|y-r(x)|\geq |s(y)-y|+|y-r(x)|=|y-r(x)|+\min\{|y-z|, z\in S_{\varepsilon}\}\geq |s(y)-r(x)|+\min\{|y-z|, z\in S_{\varepsilon}\}\geq d(S_\varepsilon,M)=\varepsilon$; pero $|x-y|+|y-r(x)|=\varepsilon$, luego $s(y)=x$, lo cual implica $x-r(x)\in (T_xS_{\varepsilon})^{\perp}$ y también $grad_xf\in T_xS_\varepsilon^\perp$. Como $S_\varepsilon$ tiene codimensión 1, la dimensión del ortogonal es 1, por lo que $grad_xf=\lambda(x-r(x))$. Así pues
\[
\lambda^2|x-r(x)|^2=\gene{grad_xf,grad_xf}=\gene{grad_xf,\lambda(x-r(x))}=\lambda \gene{grad_xf, x-r(x)}=\lambda D_xf(x-r(x)).
\]
Tomamos la curva $\alpha:I\to V-M, \alpha(t)=x+t(x-r(x))$, la cual verifica $\alpha(0)=x$ y $\alpha'(0)=x-r(x)$. Asi que $D_xf(r-r(x))=(f\circ\alpha)'(0)$, donde 
\[
f\circ\alpha(t)=|x+t(x-r(x))-r(x+t(x-r(x))|=|x+t(x-r(x))-r(x)|=|x-r(x)||1+t|=|x-r(x)|\sqrt{(1+t)^2}
\]
con lo que su derivada es $|x-r(x)|$. Finalmente $\lambda|x-r(x)|=1$, luego $grad_xf=\frac{x-r(x)}{|x-r(x)|}$, con lo que el producto escalar es 1.

Para la segunda parte, igual que antes, 
\[
D_x\varphi(grad_x\varphi)=\gene{grad_x\varphi,grad_x\varphi}=\sum_{i=1}^{k+1}\left(\parcial{\varphi}{x_i}\right)^2(x)
\]
donde $\varphi(x)=\gene{Yr(x), x-r(x)}_x$. $grad_x\varphi, Y_x\in T_{r(x)}M^\perp$, que tiene dimensión 1, luego $grad_xf=\lambda(x)Yr(x)$ donde
\[
\lambda(x)=\gene{grad_xf,Yr(x)}=D_x\varphi(Yr(x))
\]
el cual probaremos que vale 1 de la misma forma que en la primera parte. Tomamos $\alpha:V\to M, \alpha(t)=x+tYr(x)$ donde $\alpha(0)=x$ y $\alpha'(x)=Yr(x)$. 
\[
\varphi\circ\alpha(t)=\gene{Yr(\alpha(t)), \alpha(t)-r\alpha(t)}=\gene{Yr(\alpha(t), x+tYr(x)-r(x)}
\] 
luego
\[
(\varphi\circ\alpha)'(t)=\gene{Yr(\alpha(t)), Yr(x)}
\]
que al evaluarla da 1. 
\end{solucion}
\newpage

\begin{ejercicio}{9.18}
Sea $\pi:\widetilde{M}\to M$ el doble recubridor orientado del ejercicio \ref{ejer:9.15}. Sea $A:\widetilde{M}\to \widetilde{M}$ la aplicación que para cada $p\in M$ intercambia los dos puntos en $\pi^{-1}(p)$. Probar que $A$ es un difeomorfismo de orden 2 y que
\[
\Omega^r(\widetilde{M})=\Omega^r(\widetilde{M})_+\oplus\Omega^r(\widetilde{M})_-,
\]
donde $\Omega^r(\widetilde{M})_\pm$ es el subespacio propio asociado a $\pm 1$ para el isomorfismo
\[
A^*:\Omega^r(\widetilde{M})\to \Omega^r(\widetilde{M}).
\]
Probar que el complejo de deRham $(\Omega^*(\widetilde{M}),d)$ se descompone en la suma directa de dos subcomplejos
\[
(\Omega^*(\widetilde{M})_+,d)\text{ y } (\Omega^*(\widetilde{M})_-,d).
\]
Probar que $\pi^*$ es un isomorfismo entre el complejo $(\Omega^*(M),d)$ y $(\Omega^*(\widetilde{M})_+,d)$. Probar que para todo $k\in\Z$ se tiene que
\[
H^k(\pi):H^k(M)\to H^k(\widetilde{M})
\]
envía $H^k(M)$ mediante isomorfismo a al subespacio propio asociado a 1 en $H^k(\widetilde{M})$ de $H^k(A)$. 
\end{ejercicio}
\begin{solucion}
Es evidente que $A$ tiene orden 2 porque solo hay dos fibras para cada punto. Por tanto es su propia inversa y basta probar que es diferenciable para comprobar que es difeomorfismo, pero esto es claro puesto que $$\psi_{\pm}\circ A\circ\varphi_{\pm}=\psi\circ\pi\circ A\circ \pi^{-1}\circ\varphi^{-1}=\psi\circ\varphi$$
pues las proyecciones actúan igual sobre las dos fibras, es decir, $\pi\circ A=\pi$.

Como $A$ es un difeomorfismo de orden 2, $A^*:\Omega^r(\widetilde{M})\to \Omega^r(\widetilde{M})$ es un isomorfismo de orden 2, con lo que podemos descomponer $\Omega^r(\widetilde{M})=\Omega^r(\widetilde{M})_+\oplus\Omega^r(\widetilde{M})_-$ para todo $r$, donde $\Omega^r(\widetilde{M})_+=\{w\in \Omega^r(\widetilde{M})\mid A^*w=w\}$ y $\Omega^r(\widetilde{M})_-$ es su complemento ortogonal, es decir el subespacio formado por las formas diferenciales tales que $(A^*w)_{(p,o_p)}=w_{(p,-o_p)}=-w_{(p,o_p)}$.

Definimos el isomorfismo $\phi: \Omega^r(\widetilde{M})\to \Omega^r(\widetilde{M})$ como $\phi(w)=\frac{w+A^*(w)}{2}\oplus \frac{w-A^*(w)}{2}$. Con esto es claro que $d$ respeta los subespacios de forma análoga a como se hizo para el espacio proyectivo. Por tanto, se tiene la descomposición $(\Omega^*(\widetilde{M}),d)=(\Omega^*(\widetilde{M})_+,d)\oplus(\Omega^*(\widetilde{M})_-,d).$

Esto induce una descomposición similar en cohomología, $H^k(\widetilde{M})=H^k(\widetilde{M})_+\oplus H^k(\widetilde{M})_-$. 

Para probar que $\pi^*$ induce tal isomorfismo, observemos primero que como $\pi\circ A=\pi$, para cada $r$, $\Ima\pi^*\cong \{w\in \Omega^r(\widetilde{M})\mid w=A^*(w)\}=\Omega^r(\widetilde{M})_+$. Por tanto, tenemos que ver que $\pi^*$ es inyectiva. Supongamos que $\pi^*(w)=0$, entonces para todo $q=(p,o_p)\in\widetilde{M}$, $\pi^*(w)_q=0$. Equivalentemente, $\pi^*(w)_q(w_1,\dots, w_r)=w_p(D_p\pi(w_r),\dots, D_p\pi(w_r))$ para todo $w_i\in T_q\widetilde{M}$. Pero $D_p\pi$ es isomorfismo por ser $\pi$ difeomorfismo local, así que $w_p(v_1,\dots, v_p)=w_p(D_p\pi(w_r),\dots, D_p\pi(w_r))$ para todo $v_i\in T_pM$.

A partir de esto y la descomposición del complejo de cadenas se tiene directamente que $H^k(\pi)$ es un isomorfismo entre $H^k(M)$ y $H^k(\widetilde{M})_+$.
\end{solucion}
\end{document}