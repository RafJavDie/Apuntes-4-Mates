\documentclass[CV.tex]{subfiles}

\begin{document}


%\hyphenation{equi-va-len-cia}\hyphenation{pro-pie-dad}\hyphenation{res-pec-ti-va-men-te}\hyphenation{sub-es-pa-cio}

\chapter{Introducción}
\section{Álgebra alternada}
\begin{defi}
Sea $V$ un $\R$-e.v. Diremos que $f:\underbrace{V\times\dots\times V}_{r}\to\R$ es \textbf{multilineal} o $r$-lineal si lineal en cada una de sus coordenadas.

Una aplicación $r$-lineal $w:V^r\to\R$ se dirá \textbf{alternada} si $w(v_1,\dots, v_r)=0$ cuando $v_i=v_j$ para algunos $i\neq j$. 
\end{defi}

El conjunto de aplicaciones multilineales es un $\R$-e.v., $Alt^r(V)=\{w:V^r\to\R: w$ es multilineal y alternado$\}$. 
\begin{ej}
$Alt^0(V)\cong\R$, $Alt^1(V)=V^*$.
\end{ej}

\begin{lemma}
Sea $V$ tal que $\dim(V)=n$ y consideramos $Alt^r(V)$ con $r>n$. Sea $w\in Alt^r(V)$. Entonces $w\equiv 0$.
\end{lemma}
\begin{proof}
Sea $B=\{e_1,\dots, e_n\}$ base de $V$. Entonces $v_i=\sum_{j=1}^n\lambda_{ij}e_j$. Entonces
$$
w(v_1,\dots, v_r)=w\left(\sum_{j=1}^n\lambda_{1j}e_j,\dots,\sum_{j=1}^n\lambda_{rj}e_j\right)=\sum\lambda_Jw(e_{j_1},\dots, e_{j_r}),$$
donde $\lambda_J=\lambda_{j_1,1}\cdots\lambda_{j_r,r}$. Como $r>n$, entonces habrá alguna repetición entre los $e_{j_1},\dots, e_{j_r}$, por lo que se tiene el resultado.
\end{proof}

El grupo de permutaciones del conjunto $\{1,\dots, r\}$ se denotará por $S(r)$. Recordemos que toda permutación se puede escribir como composición de trasposiciones $(i,j)$. Podemos definir entonces el siguiente homomorfismo:
\begin{align*}
sgn: & S(r)\to \{1,-1\}\\
& \sigma\to sign(\sigma)
\end{align*}
tal que $sgn((i,j))=-1$, que se extiende de forma natural al resto de permutaciones.
\begin{lemma}\label{signo}
Si $w\in Alt^r(V), \sigma\in S(r)$, entonces
$$w(v_{\sigma(1)},\dots, v_{\sigma(r)})=sgn(\sigma)w(v_1,\dots, v_r).$$
\end{lemma}
\begin{proof}
Es suficiente demostrarlo para $\sigma=(i,j)$. Fijamos $(v_1,\dots, v_r)$ y definimos 
$$w_{i,j}(v,v')=(v_1,\dots,v_{i-1},v,v_{i+1},\dots, v_{j-1},v',v_{j+1},\dots, v_r).$$ 
Se tiene que $w_{i,j}\in Alt^2(V)$, de donde $w_{i,j}(v_i+v_j,v_i+v_j)=0$. Desarrollando
$$
0=w_{i,j}(v_i,v_i)+w_{i,j}(v_i,v_j)+w_{i,j}(v_j,v_i)+w_{i,j}(v_j,v_j)=w_{i,j}(v_i,v_j)+w_{i,j}(v_j,v_i).$$
De donde se deduce el resultado.
\end{proof}
\begin{ej}
Sea $V=\R^r$ y $r$ vectores $v_i=(v_{i,1},\dots, v_{i,r})$. Entonces $w(v_1,\dots, v_r)=\det(v_{i,j})$ es alternado. 
\end{ej}

\begin{defi}\label{ext}
Se define el \textbf{producto exterior} de alternados como 
$$\land:Alt(V)\times Alt(V)\to Alt^2(V)$$
dada por $w_1\land w_2(v_1,v_2)=w_1(v_1)w_2(v_2)-w_1(v_2)w_2(v_1)$. A continuación definiremos para espacios alternados de dimensión mayor.
\end{defi}
\begin{defi}
Dentro de $S(p+q)$, llamaremos $(p+q)$-\textbf{barajas} a las permutaciones de $S(p+q)$ que verifican
\begin{gather*}
\sigma(1)<\sigma(2)<\cdots<\sigma(p)\\
\sigma(p+1)<\sigma(p+2)<\cdots<\sigma(q)
\end{gather*}
Al conjunto de tales permutaciones lo denotaremos $S(p,q)$. Una $(p,q)$-baraja queda totalmente determinada por $\{\sigma(1),\dots, \sigma(p)\}$ (o por los otros). Por tanto, $Card(S(p,q))=\binom{p+q}{p}=\binom{p+q}{q}$.
\end{defi}
\begin{defi}[Producto exterior]
Dados $w_1\in Alt^p(V),w_2\in Alt^q(V)$
$$
(w_1\land w_2)(v_1,\dots, v_{p+q})=\sum_{\sigma\in S(p,q)} sgn(\sigma)w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})w_2(v_{\sigma(p+1)},\dots, v_{\sigma(p+q)}).$$
\end{defi}
Faltaría probar que $w_1\land w_2\in Alt^{p+q}(V)$, pero antes:
\begin{nota}\
\begin{enumerate}
\item Para $p=q=1$ es justamente la definición \ref{ext}. $S(1,1)=\{1,(1,2)\}$.
\item $w_1\in Alt^0(V), w_2\in Alt^1(V)\Rightarrow w_1\land w_2\in Alt^1(V)$. $S(0,1)=\{1\}$. $w_1\land w_2(v)=w_1 w_2(v)$.
\end{enumerate}
\end{nota}
Probamos ahora el resultado. 

\begin{lemma}
Sean $w_1\in Alt^p,w_2\in Alt^{q}(V)$. Entonces, $w_1\land w_2\in Alt^{p+q}$, es decir,
\begin{enumerate}
\item $w_1\land w_2$ es $(p+q)$-lineal.
\item $w_1\land w_2$ es alternado.
\end{enumerate}
\end{lemma}
\begin{proof}\
\begin{enumerate}
\item Se tiene por definición.
\item Veamos que $w_1\land w_2(v_1,v_2,\dots, v_{p+q})=0$ si $v_1=v_2$ (para cualquier otro caso será análogo). Definimos
\begin{itemize}
\item $S_{12}=\{\sigma\in S(p,q)\mid \sigma(1)=1,\sigma(p+1)=2\}$.
\item $S_{21}=\{\sigma\in S(p,q)\mid \sigma(1)=2,\sigma(p+1)=1\}$.
\item $S_0=S(p,q)-(S_{12}\cup S_{21})$.
\end{itemize}
Si $\sigma\in S_0$, entonces o bien $w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})=0$ o bien $w_2(v_{\sigma(p+1)},\dots, v_{\sigma(p+q)})=0$, pues o bien $v_{\sigma(1)}=v_{\sigma(2)}$ o bien $v_{\sigma(p+1)}=v_{\sigma(p+2)}$.
Observamos que existe una biyección $S_{12}\to S_{21}$ dada por composición por la izquierda con $\tau=(1,2)$. Por lo comentado antes, tenemos que
\begin{gather*}
w_1\land w_2(v_1,\dots, v_{p+1})=\sum_{\sigma\in S_{12}}sgn(\sigma)w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})w_2(v_{\sigma(p+1)},\dots,v_{\sigma(p+q)})+\\
\sum_{\sigma\in S_{21}}sgn(\sigma)w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})w_2(v_{\sigma(p+1)},\dots,v_{\sigma(p+q)})=\\
\sum_{\sigma\in S_{12}}sgn(\sigma)w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})w_2(v_{\sigma(p+1)},\dots,v_{\sigma(p+q)})-\\
\sum_{\tau\sigma\in S_{12}}sgn(\sigma)w_1(v_{\tau\sigma(1)},\dots, v_{\tau\sigma(p)})w_2(v_{\tau\sigma(p+1)},\dots,v_{\tau\sigma(p+q)})=0
\end{gather*}
Pues si $\sigma\in S_{12}$, entonces $\sigma(1)=1$, $\sigma(p+1)=2$, $\tau\sigma(1)=2$, $\tau\sigma(p+1)=1$, $\tau\sigma(i)=\sigma(i)\ \forall i\neq 1,p+1$. Como $v_1=v_2$, entonces $$w_1(v_{\sigma(1)},\dots,v_{\sigma(p)})w_2(v_{\sigma(p+1)},\dots, v_{\sigma(p+1)})=w_1(v_{\tau\sigma(1)},\dots, v_{\tau\sigma(p)})w_2(v_{\tau\sigma(p+1)},\dots, v_{\tau\sigma(p+q)}).$$
\end{enumerate}
\end{proof}

\begin{lemma}\label{alternado} Sea $w$ una aplicación $r$-lineal tal que $w(v_1,\dots, v_r)=0$ si $v_i=v_{i+1}$ para algún $1\leq i\leq r-1$. Entonces $w$ es alternada.
\end{lemma}
\begin{proof}
Por el argumento del lema \ref{signo}, 
$$w(v_1,\dots,v_i,v_{i+1},\dots, v_r)=-w(v_1,\dots,v_{i+1},v_i,\dots, v_r).$$
Definimos $\hat{w}(\alpha,\beta)=(v_1,\dots,v_{i-1},\alpha,\beta,\dots, v_r)\in Alt^2(V)$. Si $\sigma\in S(r)$ se verifica que
$$w(v_{\sigma(1)},\dots, v_{\sigma(r)})=sgn(\sigma)w(v_1,\dots, v_r).$$
Si $v_i=v_j$ para algún $i\neq j$, y tomamos $\sigma\in S(r)$ tal que $\sigma(i)=i, \sigma(i+1)=j$, entonces
$$w(v_{\sigma(1)},\dots,v_{\sigma(r)})=w(v_{\sigma(1)},\dots,v_i,v_j,\dots,v_{\sigma(r)})=sgn(\sigma)w(v_1,\dots, v_r)=0,$$
luego $w$ es alternada.

\end{proof}

\begin{propi} 
Sean $w_1,w_1'\in Alt^p(V)$ y $w_2,w_2'\in Alt^q(V)$. Es claro por definción que se verifican
\begin{enumerate}
\item $(w_1+w_1')\land w_2=(w_1\land w_2)+(w_1'\land w_2)$.
\item $w_1\land (w_2+w_2')=(w_1\land w_2)+(w_1\land w_2')$.
\item $\lambda\in\R$, $(\lambda w_1)\land w_2=w_1\land (\lambda w_2)=\lambda (w_1\land w_2)$.
\end{enumerate}
\end{propi}

\begin{lemma}
Si $w_1\in Alt^p(V), w_2\in Alt^q(V)$, entonces $w_1\land w_2=(-1)^{pq}w_2\land w_1$.
\end{lemma}
\begin{proof}
Sea $\tau\in S(p,q)$ tal que $\tau(1)=p+1,\dots, \tau(q)=p+q$, $\tau(q+1)=1,\dots,\tau(q+p)=p$. Tenemos que $sgn(\tau)=(-1)^{pq}$. Se induce la biyección
\begin{gather*}
S(p,q)\longrightarrow S(q,p)\\
\sigma\longmapsto \sigma\tau
\end{gather*}
Nótese que
$$w_2(v_{\sigma\tau(1)},\dots,v_{\sigma\tau(q)})=w_2(v_{\sigma(p+1)},\dots, v_{\sigma(p+q)})$$
$$w_1(v_{\sigma\tau(q+1)},\dots,v_{\sigma\tau(q+p)})=w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})$$
\begin{gather*}
w_2\land w_1(v_1,\dots, v_{p+q})=\sum_{\hat{\sigma}\in S(p,q)}sgn(\hat{\sigma})w_2(v_{\hat{\sigma}(1)},\dots, v_{\hat{\sigma}(q)})w_1(v_{\hat{\sigma}(q+1)},\dots, v_{\hat{\sigma}(p+q)})=\\
\sum_{\sigma\in S(p,q)}sgn(\sigma\tau)w_2(v_{\sigma\tau(1)},\dots, v_{\sigma\tau(q)})w_1(v_{\sigma\tau(q+1)},\dots, v_{\sigma\tau(q+p)})=\\
(-1)^{pq}\sum_{\sigma\in S(p,q)}sgn(\sigma)w_2(v_{\sigma(p+1)},\dots,v_{\sigma(p+q)})w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})=\\
(-1)^{pq}w_1\land w_2(v_1,\dots, v_{p+q})
\end{gather*}
\end{proof}

\begin{lemma}
Sean $w_1\in Alt^p(V)$, $w_2\in Alt^q(V)$, $w_3\in Alt^r(V)$, entonces

$$w_1\land (w_2\land w_3)=(w_1\land w_2)\land w_3.$$
\end{lemma}
\begin{proof}
Sea $S(p,q,r)\subseteq S(p+q+r)$ el conjunto de permutaciones $\sigma$ tales que
\begin{gather*}
\sigma(1)<\cdots\sigma(p)\\
\sigma(p+1)<\cdots\sigma(p+q)\\
\sigma(p+q+1)<\cdots\sigma(p+q+r)
\end{gather*}
Sea $S(\hat{p}, q,r)\subseteq S(p,q,r)$ las permutciones $\sigma\in S(p,q,r)$ tales que $\sigma(1)=1,\dots,\sigma(p)=p$ y $S(p,q,\hat{r})$ aquellas tales que $\sigma(p+q+1)=p+q+1,\dots, \sigma(p+q+r)=p+q+r$. Tenemos las siguientes biyecciones
\begin{gather*}
S(p,q+r)\times S(\hat{p},q,r)\longrightarrow S(p,q,r)\\
(\sigma,\tau)\longmapsto \sigma\tau
\end{gather*}
\begin{gather*}
S(p+q,r)\times S(p,q,\hat{r})\longrightarrow S(p,q,r)\\
(\sigma,\tau)\longmapsto \sigma\tau
\end{gather*}
\begin{gather*}
w_1\land (w_2\land w_3)(v_1,\dots, v_{p+q+r})=\sum_{\sigma\in S(p,q+r)}sgn(\sigma)w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})[w_w\land w_3(v_{\sigma(p+q)},\dots, v_{\sigma(p+q+r)})]=\\
\sum_{\sigma\in S(p,q+r)}sgn(\sigma)w_1(v_{\sigma(1)},\dots, v_{\sigma(p)})\sum_{\tau\in S(\hat{p},q,r)}sgn(\tau)w_2(v_{\sigma\tau(p+1)},\dots, v_{\sigma\tau(p+q)})w_3(v_{\sigma\tau(p+q+1)},\dots, v_{\sigma\tau(p+q+r)})
\end{gather*}
Como $\tau$ deja fijos los $p$ primero, tenemos que esto es igual a 
\begin{gather*}
\sum_{\sigma\in S(p,q+r)}\sum_{\tau\in S(\hat{p},q,r)}sgn(\sigma\tau)w_1(v_{\sigma\tau(1)},\dots, v_{\sigma\tau(p)})w_2(v_{\sigma\tau(p+1)},\dots, v_{\sigma\tau(p+q)})w_3(v_{\sigma\tau(p+q+1)},\dots, v_{\sigma\tau(p+q+r)})=\\
\sum_{\hat{\sigma}\in S(p,q,r)} sgn(\hat{\sigma})w_1(v_{\hat{\sigma}(1)},\dots, v_{\hat{\sigma}(p)})w_2(v_{\hat{\sigma}(p+1)},\dots, v_{\hat{\sigma}(p+q)})w_3(v_{\hat{\sigma}(p+q+1)},\dots, v_{\hat{\sigma}(p+q+r)})=\\
(w_1\land w_2)\land w_3(v_1,\dots, v_{p+q+r})
\end{gather*}
La última igualdad se tiene al realizar el proceso análogo con $(w_1\land w_2)\land w_3(v_1,\dots, v_{p+q+r})$.
\end{proof}

\begin{defi}
Una \textbf{$k$-álgebra} $A$ es un $k$-espacio vectorial con una aplicación bilineal 
$$\mu:A\times A\to A$$
que sea asociativa, es decir, $\mu(a,\mu(b,c))=\mu(\mu(a,b),c)\ \forall a,b,c\in A$. Si además existe $1\in A$ tal que $\mu(1,a)=\mu(a,1)=a$, entonces se dirá que $A$ es un \textbf{álgebra unitaria}.

Diremos que $A_*$ es un \textbf{álgebra graduada} si $A_*=\oplus_{r\geq 0}A_r$ tal que $\mu:A_r\times A_l\to A_{r+l}$ son bilineales y asociativas, con los $A_r$ espacios vectoriales.

Un álgebra graduada $A_*$ se dice \textbf{conexa} (o coercitiva) si $1\in A_0$ y si existe $\varepsilon:k\to A_0$ que es isomorfismo dado por $\varepsilon(r)=r\cdot 1$.

El álgebra $A_*$ se dirada \textbf{graduada conmutativa} (anticonmutativa, skew-algebra) si $\mu(a,b)=(-1)^{rl}\mu(b,a)$, $a\in A_r,b\in A_l$. 
\end{defi}
\begin{nota} Los elementos $a\in A_r$ se dirá que tienen grado $r$.
\end{nota}

\begin{teorema}
$Alt^*(V)=\bigoplus_{r\geq 0} Alt^r(V)$ es un $\R$-álgebra graduada, anticonmutativa y conexa.
\end{teorema}
\begin{lemma}
Sean $w_1,\dots, w_p\in Alt^1(V)$. Entonces 
$$w_1\land w_p(v_1,\dots, v_p)=\det\begin{pmatrix}
w_1(v_1) &\dots & w_1(v_p)\\
\vdots & & \vdots\\
w_p(v_1) & \dots & w_p(v_p)
\end{pmatrix}.$$
\end{lemma}
\begin{proof}
Para $p=2$, $w_1\land w_2(v_1,v_2)=w_1(v_1)w_2(v_2)-w_1(v_2)w_2(v_1)$, así que es cierto.
Supongámos ahora que es cierto para $p-1$. Usamos la asociatividad
\begin{gather*}
w_1\land (w_2\land\dots\land w_p)(v_1,\dots, v_p)=\sum_{j=1}^p(-1)^{j-1}w_1(v_j)w_2(v_1,\dots, \hat{v}_j,\dots, v_p)
\end{gather*}
donde el gorro significa que se elimina ese elemento. Esto es justamente el desarrollo del determinante que buscamos.
\end{proof}
Se sigue que si $w_1,\dots, w_p\in Alt^1(V)$ son linealmente independientes, entonces $w_1\land\dots\land w_p\neq 0$. Basta encontrar un conjunto de vectores sobre los que el determinante no se anulen, y estos son los duales correspondientes. Recíprocamente, si $w_1,\dots, w_p$ son linealmente dependientes, entonces $w_1\land\dots\land w_p=0$. 

\begin{teorema}
Sea $\{e_1,\dots, e_n\}$ una base de $V$ y $\{\varepsilon_1,\dots, \varepsilon_n\}$ la base dual correspondiente en $Alt^1(V)=V^*$. Entonces 
$$\{\varepsilon_{\sigma(1)}\land\dots\land\varepsilon_{\sigma(p)}\}_{\sigma\in S(p,n-p)}$$
es base de $Alt^p(V)$. En particular $\dim(Alt^p(V))=\binom{n}{p}$. En el caso $\dim(Alt^n(V))=1$, la base es $\varepsilon_1\land\dots\land\varepsilon_n$ y es isomorfo a $\R$.
\end{teorema}
\begin{dem}
Si $w\in Alt^p(V)$, entonces
\begin{equation}\label{generador}
w=\sum_{\sigma\in S(p,n-p)}w(e_{\sigma(1)},\dots,e_{\sigma(p)})\varepsilon_{\sigma(1)}\land\dots\land\varepsilon_{\sigma(p)}.
\end{equation}
Esto significa que $\{\varepsilon_{\sigma(1)}\land\dots\land\varepsilon_{\sigma(p)}\}_{\sigma\in S(p,n-p)}$ es sistema generador. Es también linealmente independiente pues si
$$\sum_{\sigma\in S(p,n-p)}\lambda_{\sigma}\varepsilon_{\sigma(1)}\land\dots\land\varepsilon_{\sigma(p)}=0\in Alt^p(V)$$
fijamos $\hat{\sigma}\in S(p,n-p)$ y evaluamos.
$$\sum_{\sigma\in S(p,n-p)}\lambda_{\sigma}\varepsilon_{\hat{\sigma}(1)}\land\dots\land\varepsilon_{\hat{\sigma}(p)}$$
 Como $\varepsilon_i(v_j)=\delta_{ij}$, cada término de la suma no se anula solo si los índices coinciden, es decir, cuando $\sigma=\hat{\sigma}$, luego nos queda que el coeficiente que no se anulaba debe ser 0.
 
Vamos a probar \ref{generador}. Sea $(v_1,\dots, v_p)\in V^p$, entonces $v_i=\sum_{r=1}^n\lambda_{i,r}e_r$. Entonces
\begin{gather*}
w(v_1,\dots, v_p)=w(\sum_{r=1}^n\lambda_{1,r}e_r,\dots, \sum_{r=1}^n\lambda_{p,r}e_r)=\\
\sum_K\prod_{j=1}^n\lambda_{j,r(j)}w(e_{r(1)},\dots, e_{r(p)})
\end{gather*}
donde $K=\{(r(1),\dots, r(p)):1\leq r(j)\leq n, r(i)\neq r(j)\ \forall i\neq j\}$. Probemos que hay una biyección entre $K$ y $S(p,n-p)$, con lo cual tendremos el resultado. La diferencia entre $K$ y $S(p,n-p)$, es que las uplas del primer conjunto no están ordenadas, pero podemos cambiar el orden de la siguiente forma. $(r(1),\dots, r(j)\Rightarrow\exists!\sigma\in S(p,n-p)$ tal que $\{\sigma(1),\dots, \sigma(j)\}=\{r(1),\dots, r(p)\}$. Luego $\exists!\tau\in S(p)$ tal que $\sigma\tau(1)=r(1),\dots, \sigma\tau(p)=r(p)$. Podemos interpretar $\tau$ en $S(n)$ simplemente fijando los elementos que faltan cuando sea necesario, pues $S(p,n-p)\subset S(n)$. De esta forma tenemos una biyección. 

Entonces podemos reescribir
\begin{gather*}
\sum_K\prod_{j=1}^n\lambda_{j,r(j)}w(e_{r(1)},\dots, e_{r(p)})=\sum_{\sigma\in S(p,n-p)}\sum_{\tau\in S(p)}\prod_{j=1}^n\lambda_{j,\sigma\tau(j)}w(e_{\sigma\tau(1)},\dots, e_{\sigma\tau(p)})=\\
\sum_{\sigma\in S(p,n-p)}\sum_{\tau\in S(p)}\prod_{j=1}^p\lambda_{j,\sigma\tau(j)}w(e_{\sigma(1)},\dots, e_{\sigma(p)})
\end{gather*}
Obsérvese que si llamamos $\alpha=\sigma\tau^{-1}\sigma^{-1}$, entonces $sgn(\alpha)=sgn(\tau^{-1})=sgn(\tau)$. Así, 
\begin{gather*}
w(e_{\sigma\tau(1)},\dots, e_{\sigma\tau(p)})=sgn(\alpha)w(e_{\alpha\sigma\tau(1)},\dots, e_{\alpha\sigma\tau(p)})=sgn(\tau)w(e_{\sigma(1)},\dots,e_{\sigma(p)})
\end{gather*}
Entonces,
\begin{gather*}
\sum_{\sigma\in S(p,n-p)}\sum_{\tau\in S(p)}\prod_{j=1}^p\lambda_{j,\sigma\tau(j)}w(e_{\sigma(1)},\dots, e_{\sigma(p)})=\sum_{\sigma\in S(p,n-p)}\sum_{\tau
\in S(p)}sgn(\tau)\prod_{j=1}^p\lambda_{j,r(j)}w(e_{\sigma(1)},\dots, e_{\sigma(p)})=\\
\sum_{\sigma\in S(p,n-p)}w(e_{\sigma(1)},\dots, e_{\sigma(p)})\left(\sum_{\tau\in S(p)}sgn(\tau)\prod_{j=1}^p\lambda_{j,\sigma\tau(j)}\right)=\\
\sum_{\sigma\in S(p,n-p)}w(e_{\sigma(1)},\dots, e_{\sigma(p)})\det\begin{pmatrix}
\lambda_1\sigma(1) & \dots & \lambda_1\sigma(p)\\
\vdots & & \vdots\\
\lambda_p\sigma(1) & \dots & \lambda_p\sigma(p)
\end{pmatrix}=\\
\sum_{\sigma\in S(p,n-p)}w(e_{\sigma(1)},\dots, e_{\sigma(p)}\det\begin{pmatrix}
\varepsilon_{\sigma(1)}(v_1) & \cdots & \varepsilon_{\sigma(p)}(v_1)\\
\vdots & & \vdots\\
\varepsilon_{\sigma(1)}(v_1) & \cdots & \varepsilon_{\sigma(p)}(v_p)
\end{pmatrix}
\end{gather*}
donde $\varepsilon_j$ es el dual de $e_j$. Recordar que $\varepsilon_j(v_i)=\varepsilon_j(\sum\lambda_{i,k}e_k)=\lambda_{i,j}\varepsilon_j(e_j)$. \QED
\end{dem}

Sea $f:V\to W$ un $\R$-homomorfismo de e.v. Entonces, para $p\in\N$, 
\begin{align*}
Alt^p(f): Alt^p(W)\to Alt^p(V)
\end{align*}
se define como la aplicación $Alt^p(f)(w)(v_1,\dots, v_p)=w(f(v_1),\dots, f(v_p))$.

\begin{propi}
Se verifican:
\begin{enumerate}
\item $Alt^p(f)$ es $\R$-homomorfismo.
\item $Alt^p(g\circ f)=Alt^p(f)\circ Alt^p(g)$.
\item $Alt^p(Id_V)=Id_{Alt^p(V)}$
\item $Alt^{p+q}(f)(w_1\land w_2)=Alt^p(f)(w_1)\land Alt^q(f)(w_2)$. 
\end{enumerate}
\end{propi}
\begin{dem}
\begin{enumerate}
\item $Alt^p(f)(w_1+w_2)(v_1,\dots, v_p)=(w_1+w_2)(f(v_1),\dots, f(v_p))=w_1(f(v_1),\dots, f(v_p))+w_2(f(v_1),\dots, f(v_p))=Alt^p(f)(w_1)(v_1,\dots, v_p)+Alt^p(f)(w_2)(v_1,\dots, v_p)$.
\item 

$Alt^p(g\circ f)(w)(v_1,\dots, v_p)=w(g(f(v_1)),\dots, g(f(v_p)))=Alt^p(g)(w(f(v_1),\dots, f(v_p))=Alt^p(f)\circ Alt^p(g)(w)(v_1,\dots, v_p)$


\item $Alt^p(Id_V)(w)(v_1,\dots, v_p)=w(v_1,\dots, v_p)=Id_{Alt^p(V)}(w)(v_1,\dots, v_p)$.

\item \begin{gather*}
Alt^{p+q}(f)(w_1\land w_2)(v_1,\dots, v_{p+q})=w_1\land w_2(f(v_1),\dots, f(v_{p+q})=\\
\sum_{\sigma}sgn(\sigma)w_1(f(v_{\sigma(1)}),\dots, f(v_{\sigma(p)}))w_2(f(v_{\sigma(p+1)}),f(v_{\sigma(p+q}))=\\
\sum_{\sigma}sgn(\sigma) Alt^p(f)(w_1)(v_{\sigma(1)},\dots, v_{\sigma(p)})Alt^q(f)(w_2)(v_{\sigma(p+1)},\dots, v_{\sigma(p+q)})=\\
Alt^p(f)(w_1)\land Alt^q(f)(w_2)(v_1,\dots, v_{p+1})
\end{gather*}
\QED
\end{enumerate}
\end{dem}

Tenemos entonces un functor contravariante $Alt^*$ entre $\R$-espacios vectoriales y $\R$-álgebras graduadas, conexas y anticonmutativas.

Sea $f:V\to V$ homomorfismo con $\dim(V)=n$. Entonces $Alt^n(f):Alt^n(V)\to Alt^n(V)$, $\dim(Alt^n(V))=1$ con base $\{\varepsilon_1\land\dots\land\varepsilon_n\}$. Llamamos $d=\det(f)$. Entonces deberá ser $Alt^n(f)(\varepsilon_1\land\dots\land\varepsilon_n)=d(\varepsilon_1\land\dots\land\varepsilon_n)$. Comprobémoslo. Usamos como base para la matriz de $f$ el conjunto $\{e_1,\dots, e_n\}$.
\begin{gather*}
Alt^n(f)(\varepsilon_1\land\dots\land\varepsilon_n)(v_1,\dots, v_p)=\varepsilon_1\land\dots\land \varepsilon_n(f(v_1),\dots, f(v_n))=\\
\det\begin{pmatrix}
\varepsilon_1(f(v_1)) & \dots & \varepsilon_1(f(v_n))\\
\vdots & & \vdots\\
\varepsilon_n(f(v_1)) & \dots & \varepsilon_n(f(v_n))
\end{pmatrix}=\det\begin{pmatrix}
f(v_1)_1 & \dots & f(v_n)_1\\
\vdots & & \vdots\\
f(v_1)_n & \dots & f(v_n)_n
\end{pmatrix}=\\
\det\left(\begin{pmatrix}
f(e_1)_1 & \dots & f(e_n)_1\\
\vdots & & \vdots\\
f(e_n)_1 & \dots & f(e_n)_n
\end{pmatrix}\begin{pmatrix}
(v_1)_1 & \dots & (v_n)_1\\
\vdots & & \vdots\\
(v_n)_1 & \dots & (v_n)_n
\end{pmatrix}\right)=\det(f)\det\begin{pmatrix}
(v_1)_1 & \dots & (v_n)_1\\
\vdots & & \vdots\\
(v_n)_1 & \dots & (v_n)_n
\end{pmatrix}=\\d\det\begin{pmatrix}
\varepsilon_1(v_1) & \dots &\varepsilon_1(v_n)\\
\vdots & &\vdots \\
\varepsilon_n(v_1) & \cdots & \varepsilon_n(v_n)
\end{pmatrix}=d (\varepsilon_1\land\dots\land\varepsilon_n)(v_1,\dots, v_n)
\end{gather*}



\end{document}
