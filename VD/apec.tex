\documentclass[cursovd_portada.tex]{subfiles}

\begin{document}

\chapter*{Apéndice C.\\\'Algebra Tensorial y Exterior de un Espacio Vectorial}
\addcontentsline{toc}{chapter}{Apéndice C. álgebras Tensorial y Exterior de un Espacio Vectorial.}
\section*{C.1 álgebra Tensorial de un Espacio Vectorial.}
\addcontentsline{toc}{section}{C.1\hspace{0.5 em} álgebra Tensorial de un Espacio Vectorial.} \hs En este apéndice
$V$ denotará un espacio vectorial de dimensión $n$ sobre el cuerpo de los números reales.
\begin{defiap}
Dado $r\in\N$, sea $T^0_r(V)=\{f:V^r\fl\R / f \mbox{ es r--lineal}\}$. Los elementos de $T^0_r(V)$ se llaman {\bf
Tensores Covariantes de Tipo $(0,r)$}.
\end{defiap}
\par\bigskip
Obsérvese que $T^0_1(V)=V^*$. Además, se tiene que la familia $\{T^0_r(V)/r\in\N\}$ es numerable y está formada
por espacios vectoriales reales, pues la suma y el producto por un escalar de aplicaciones $r$-- lineales es una
aplicacion $r$--lineal. Así, se puede considerar su suma directa,
$$\bigoplus_{r=0}^\infty T^0_r(V),$$
que se denomina {\bf Algebra de los Tensores Covariantes} de $V$. A con\-ti\-nua\-ción, se va a justificar que,
efectivamente, es un álgebra. En efecto, en dicha suma infinita (recuérdese que sus elementos tienen solo un
número finito de sumandos no nulos) está definida de modo natural una suma y un producto por números reales, que
la convierten en un espacio vectorial real.
\begin{defiap}
Sean $\omega_r\in T^0_r(V)$, $\omega_s\in T^0_s(V)$. Se llama {\bf Producto Tensorial de $\omega_r$ y $\omega_s$},
que se denota por $\omega_r\otimes \omega_s$ a un elemento de $T^0_{r+s}(V)$, que será tal que si
$$(v_1,\dots ,v_r,v_{r+1},\dots ,v_{r+s})\in V^{r+s},$$
entonces:
$$(\omega_r\otimes\omega_s)(v_1,\dots ,v_r,v_{r+1},\dots ,v_{r+s})=
\omega_r(v_1,\dots ,v_r)\omega_s(v_{r+1},\dots,v_{r+s}).$$
\end{defiap}
\par\bigskip
En particular, $T_0^0(V)=\R$ y si $\a\in T^0_0(V)$, se tiene que $\a\otimes \omega_r=\a\cdot\omega_r$. Con esto,
es posible definir el producto $\otimes$, llamado producto tensorial, en los elementos de $\bigoplus T^0_r(V)$, como:
$$\left(\sum_{r=0}^\infty\omega_r\right)\otimes\left(\sum_{s=0}^\infty\omega_s\right)=\sum_{r,s=0}^
\infty\omega_r\otimes\omega_s.$$
\begin{propoap} Se verifica que
$$\bigoplus_{r=0}^\infty T^0_r(V)$$
con las operaciones $(+,\cdot,\otimes)$ es un álgebra real, asociativa, no conmutativa y con elemento unidad.
\end{propoap}
{\sc Demostración:} Es una comprobación engorrosa, pero fácil.\hfill$\Box$
\par\bigskip
El siguiente paso consiste en buscar una base para $T^0_r(V)$. Para ello, sean $\{e_1,\dots ,e_n\}$ una base de V
y $\{\theta^1,\dots ,\theta^n\}$ su base dual (base de $V^*$ con $\theta^i(e_j)=\delta_{ij}$, $\forall i,j=1,\dots
, n$). Sean ahora $i_1,\dots ,i_r\in \{1,\dots, n\}$. Entonces, el producto tensorial
$\theta^{i_1}\otimes\cdots\otimes\theta^{i_r}$ es un elemento de $T^0_r(V)$, precisamente es el que cumple:
$$(\theta^{i_1}\otimes\cdots\otimes\theta^{i_r})(v_1,\dots,v_r)
=\theta^{i_1}(v_1)\cdots\theta^{i_r}(v_r).$$ En estas condiciones, se puede probar el siguiente resultado:
\begin{propoap}
La familia
$$\{\theta^{i_1}\otimes\cdots\otimes\theta^{i_r}/i_1,\dots ,i_r\in\{1,\dots,
n\}\}$$ es una base de $T^0_r(V)$ y, por tanto, $\dim T^0_r(V)=n^r$.
\end{propoap}
{\sc Demostración:} !`Ejercicio! \hfill$\Box$
\par\bigskip
Obsérvese, entonces, que $\bigoplus_{r=0}^{\infty}T^0_r(V)$ es de dimensión infinita.
\begin{defiap}
Sea $r\in\N$. Entonces, a los elementos de $T^r_0(V) = T^0_r(V^*)$ se le llaman {\bf Tensores Contravariantes de
Tipo $(r,0)$} y al espacio
$$\bigoplus_{r=1}^\infty T^r_0(V)$$
se denomina {\bf Algebra de los Tensores Contravariantes de $V$}.
\end{defiap}
\par\bigskip
En virtud de esta definición, un número real es un tensor covariante y \underline{no} contravariante. Así,
$$\bigoplus_{r=1}^{\infty} T^r_0(V)$$
es un álgebra asociativa, no conmutativa y \underline{sin} elemento unidad. Además, $T^1_0(V) =T^0_1(V^*) =V$. Por
tanto, se puede considerar el producto tensorial de dos vectores de $V$.
\par
Se obtiene una igualdad curiosa al considerar $v_1,\dots ,v_r \in V$ y $\omega^1,\dots ,\omega^r\in V^*$.
Entonces, $v_1\otimes\cdots\otimes v_r\in T^r_0(V)$ y $\omega^1\otimes\cdots\otimes\omega^r\in T^0_r(V)$ y:
$$(v_1\otimes\cdots\otimes v_r)(\omega^1,\dots ,\omega^r)=
v_1(\omega^1)\dots v_r(\omega^r)=$$
$$=\omega^1(v_1)\dots\omega^r(v_r)=(\omega^1\otimes\cdots\otimes\omega^r)(v_1,
\dots ,v_r).$$ \hs Igual que se hizo antes, si $\{e_1, \dots e_n\}$ es una base de $V$, se tiene que
$$\{e_{i_1}\otimes\cdots\otimes e_{i_r}/i_1,\dots ,i_r\in\{1,\dots ,n\}\}$$
es una base de $T^r_0(V)$ y si $T\in T^r_0(V)$, su expresión en esa base es:
$$T=\sum_{i_1,\dots,i_r=1}^{n}T(\theta^{i_1},\dots ,\theta^{i_r})e_{i_1}
\otimes\cdots\otimes e_{i_r}.$$ \hs Se va a completar este estudio con la introducción de una nueva clase más
general de tensores:
\begin{defiap}
Sean $r,s\in\N$. Entonces, los elementos de
$$T^r_s(V)=\{f:V^s\times V^{*r}\fl\R /f\mbox{ }es\mbox{ }(s+r)\mbox{--}lineal
\}$$ se llaman {\bf Tensores Mixtos de Tipo $(r,s)$}. Además, al conjunto
$$T(V)=\bigoplus_{r,s\in\N}T^r_s(V)$$
se le denomina {\bf Algebra Tensorial de $V$}.
\end{defiap}
\par\bigskip
Se define el producto tensorial en $T(V)$ como sigue. Si $T\in T^r_s(V)$ y $S \in T^{r'}_{s'}$, entonces $T\otimes
S\in T^{r+r'}_{s+s'}(V)$ viene dado por
$$(T\otimes S)(v_1,\dots, v_s,v_{s+1},\dots ,v_{s+s'},\omega^1,\dots\omega^r,
\omega^{r+1},\dots ,\omega^{r+r'})=$$
$$=T(v_1,\dots ,v_s,\omega^1,\dots ,\omega^r)S(v_{s+1},\dots, v_{s+s'},\omega^
{r+1},\dots ,\omega^{r+r'})$$ y se extiende a $T(V)$ por linealidad:
$$\left(\sum_{r,s}T_{(r,s)}\right)\otimes\left(\sum_{r',s'}S_{(r',s')}\right)=\sum_{r,s,r',s'}T_{(
r,s)}\otimes S_{(r',s')}.$$

\newpage

\begin{propoap}
$T(V)$ es un álgebra asociativa, no conmutativa y con elemento unidad.
\end{propoap}
{\sc Demostración:} Es una comprobación engorrosa pero fácil.\hfill$\Box$ \par\bigskip Una base de $T^r_s(V)$
viene dada por el conjunto de los tensores
$$\{e_{i_1}\otimes\cdots\otimes e_{i_r}\otimes\theta^{j_1}\otimes\cdots\otimes
\theta^{j_s}/i_1,\dots ,i_r,j_1,\dots ,j_s\in\{1,\dots,n\}\}$$ y, por tanto, $\dim T^r_s(V)=n^{r+s}$. La expresión
de $T\in T^r_s(V)$ en esta base es:
$$T=\sum_{i_1,\dots ,i_r,j_1,\dots ,j_s=1}^nT(e_{j_1},\dots ,e_{j_s},\theta^
{i_1},\dots ,\theta^{i_r})e_{i_1}\otimes\cdots\otimes e_{i_r}\otimes\theta^
{j_1}\otimes\cdots\otimes\theta^{j_s}.$$ \hs A continuación, se va a demostrar que las matrices pueden ser
consideradas como una clase de tensores.
\begin{propoap}
$T^1_r(V)$ es isomorfo al espacio de todas las aplicaciones $r$--li\-nea\-les de $V^r$ en $V$, ${\cal L}(V^r,V)$.
\end{propoap}
{\sc Demostración:} Considérense las aplicaciones
$$\vp:{\cal L}(V^r,V)\fl T^1_r(V):f\mapsto\vp(f)/\vp(f)(v_1,\dots ,
v_r,\omega)=\omega(f(v_1,\dots ,v_r))$$ y
$$\psi:T^1_r(V)\fl{\cal L}(V^r,V):T\mapsto\psi(T)/\psi(T)(v_1,\dots ,
v_r)=T(v_1,\dots ,v_r,\bullet)$$ donde $T(v_1,\dots ,v_r,\bullet):V^*\fl\R$ es lineal, es decir, $\psi(T)(v_1,
\dots ,v_r)\in V^{**}=V$. Para terminar, debe probarse (!`hacerlo!) que $\vp$ y $\psi$ son inversas una de la otra
y que $\vp$ es un homomorfismo (?`por qué basta con ésto?). \hfill$ \Box$
\begin{coroap}
$$T^1_1(V)\simeq End(V).$$
\end{coroap}
\par\bigskip
Así, las matrices cuadradas de orden $n$ pueden ser consideradas como tensores de tipo $(1,1)$. En este sentido,
los tensores son una generalización de las matrices. Por otra parte, en las matrices cuadradas se llama traza a la
suma de los elementos de la diagonal principal. Este concepto se generaliza en los tensores como sigue. Sean
$r,s\in\N$ y $T\in T^r_s(V)$. Entonces, para $1\leq i\leq r$, $1\leq j\leq s$, se tiene la siguiente definición:

\newpage

\begin{defiap}
Se llama {\bf Contracción $(i,j)$ del tensor $T$} al tensor
$$C^i_j(T)\in T^{r-1}_{s-1}(V),$$
que actúa como:
$$C^i_j(T)(v_1,\dots ,v_{s-1},\omega^1,\dots ,\omega^{r-1})=$$
$$=\sum_{k=1}^nT(v_1,\dots ,v_{j-1},e_k,v_j,...v_{s-1},\omega^1,\dots ,\omega^
{i-1},\theta^k,\omega^i,\dots ,\omega^{r-1}).$$
\end{defiap}
\par\bigskip
Existen, por tanto, $rs$ contracciones de un tensor del tipo $(r,s)$. Sea, ahora, $A=(a_{ij})$ una matriz cuadrada
de orden $n$. Se puede considerar $A \in T^1_1(V)$. Así, sólo existe una contracción de $A$, $C^1_1(A)\in T^0_0(V)
=\R$,
$$C^1_1(A)=\sum_{k=1}^nA(e_k,\theta^k)=\sum_{k=1}^n\theta ^k(Ae_k)=
\sum_{k=1}^n\theta^k(\sum_{j=1}^na_{jk}e_j)=\sum_{k=1}^na_{kk},$$ que es, efectivamente, la traza de $A$.
\par
Por último, se va a introducir otro concepto que también es una ge\-ne\-ra\-li\-za\-ción de algo conocido. Se sabe
que dado un homomorfismo entre dos espacios vectoriales, $f:V\fl W$, existe un homomorfismo inducido entre los
espacios duales $f^*:W^*\fl V^*$, denominado homomorfismo dual, definido por $f^*( \omega)v=\omega(f(v))$. Como el
dual de un espacio vectorial es el espacio vectorial de los tensores de tipo $(0,1)$, se puede escribir
$f^*:T^0_1(W)\fl T^0_1(V)$. Esto se generaliza para cualquier $r\in\N$:
\begin{defiap}
Si $f\in Hom(V,W)$, entonces $f^*:T^0_r(W)\fl T^0_r(V)$, es el homomorfismo tal que a $T\in T^0_r(W)$ le asigna el
tensor $f^*_r(T)\in T^0_r(V)$ definido como:
$$f^*_r(T)(v_1,\dots ,v_r)=T(f(v_1),\dots ,f(v_r)).$$
\hs La aplicación $f^*_r$ se denomina {\bf Homomorfismo Inducido}. En particular, $f^*_1=f^*$.
\end{defiap}
\section*{C.2 álgebra Exterior de un Espacio Vectorial.}
\addcontentsline{toc}{section}{C.2\hspace{0.5 em} álgebra Exterior de un Espacio Vectorial.} \hs Sean $r\in\N$ y
${\cal S}_r$ el grupo de las permutaciones del conjunto $\{1,2,\dots ,r\}$. Si $\sigma\in{\cal S}_r$,
$\varepsilon(\sigma)$ representará el signo de $\sigma$.
\begin{defiap}
Un tensor $f\in T^0_r(V)$, se dirá que es un {\bf Tensor Alternado} si se verifica
$$f(v_1,\dots ,v_r)=\varepsilon(\sigma)f(v_{\sigma (1)},\dots ,v_{\sigma (r)}),$$
$\forall (v_1,\dots ,v_r)\in V^r$ y $\forall\sigma\in{\cal S}_r$.
\end{defiap}
\par\bigskip
Los tensores alternados forman un subespacio vectorial de $T^0_r(V)$ que se denotará por $\Lambda_r(V)$.
Claramente, $\Lambda _0(V)=\R$. Utilizando la definición anterior, también es obvio que $\Lambda
_1(V)=T^0_1(V)=V^*$, es decir, todo tensor covariante de orden uno es necesariamente alternado (?`por qué?).
\begin{defiap}
Al espacio
$$\Lambda (V)=\bigoplus_{r=0}^\infty\Lambda_r(V)$$
se le llama {\bf Algebra Exterior de $V$}.
\end{defiap}
\par\bigskip
Evidentemente, $\Lambda (V)$ es un espacio vectorial. A continuación, se va a definir en él un producto que lo va
a convertir en un álgebra. Para ello, será necesario un nuevo concepto que se pasa a definir.
\begin{defiap}
Para $r\in\N$, sea la aplicación $Alt_r:T^0_r(V)\fl\Lambda _r(V)$, que actúa de la siguiente manera:
$$Alt_r(T)(v_1,\dots ,v_r)=\frac{1}{r!}\sum_{\sigma\in{\cal S}_r}\varepsilon(
\sigma)T(v_{\sigma(1)},\dots ,v_{\sigma(r)}).$$ \hs $Alt_r(T)$ se denomina {\bf Alternacion del Tensor $T$}.
\end{defiap}
\par\bigskip
En estas condiciones, se tiene la siguiente proposición, cuya demostración queda como ejercicio:
\begin{propoap}
\begin{enumerate}
\item[(i)] La aplicación $Alt_r$ es, $\forall r\in\N$, un homomorfismo de
espacios vectoriales y restringido a $\Lambda_r(V)$ es la identidad.
\item[(ii)] Si $Alt_r(T)=0$, entonces, $\forall S\in T^0_s(V)$, $Alt_{r+s}(T
\otimes S)=0$.
\end{enumerate}
\end{propoap}
\par\bigskip
De la (i), se deduce que
$$\Lambda_r(V)\simeq\frac{T^0_r(V)}{{\rm Ker}(Alt_r)},$$
en virtud del Primer Teorema de Isomorfía de espacios vectoriales.
\par
A partir de ahora y salvo en caso de confusión, se eliminará el subíndice de la notación.
\par
Ahora, se va a definir el {\bf Producto Exterior} de tensores covariantes alternados. Igual que en el caso del
producto tensorial, se hará en dos etapas. En primer lugar, si $\omega\in\Lambda_r(V)$ y $\theta\in\Lambda_s(V)$,
el producto exterior de $\omega$ por $\theta$ se denota por $\omega\wedge \theta$ y es, por definición, el
elemento de $\Lambda_{r+s}(V)$, dado por:
$$\omega\wedge\theta=\frac{(r+s)!}{r!s!}Alt(\omega\otimes\theta).$$
\hs Utilizando la definición de alternación, se tiene que:
$$(\omega\wedge\theta )(v_1,\dots ,v_{r+s})=\frac{1}{r!s!}\sum_{\sigma\in{\cal
S}_{r+s}}\varepsilon(\sigma)\omega(v_{\sigma (1)},\dots ,v_{\sigma (r)})\theta(v_ {\sigma (r+1)},\dots ,v_{\sigma
(r+s)}).$$ \hs A continuación, el producto de dos elementos genéricos
$$\sum_{r=0}^{\infty}\omega_r\mbox{ }\mbox{y}\mbox{ }\sum_{s=0}^{\infty}\theta_s$$
de $\Lambda (V)$ se define a partir de lo anterior como:
$$\left(\sum_{r=0}^{\infty}\omega_r\right)\wedge \sum_{s=0}^{\infty}\theta_s)=\sum_
{r,s=0}^{\infty}\omega_r\wedge\theta _s.$$ \hs Es fácil probar (?`por qué?) que si $\omega\in\Lambda_r(V)$ y
$\theta\in\Lambda _s(V)$, entonces $\omega\wedge\theta=(-1)^{rs}\theta\wedge\omega$. Obsérvese que si $r$ ó $s$ es
par, entonces $\omega\wedge\theta=\theta\wedge\omega$. En cambio, si $r$ y $s$ son impares,
$\omega\wedge\theta=-\theta\wedge\omega$. En particular, si $\omega\in\Lambda_{2r+1}$, entonces
$\omega\wedge\omega=0$.
\begin{propoap}
$\Lambda (V)$ con el producto exterior es un álgebra asociativa, no conmutativa y con elemento unidad.
\end{propoap}
{\sc Demostración:} !`Ejercicio!.\hfill$\Box$
\par\bigskip
Haciendo una prueba por inducción, se tiene la siguiente proposición:
\begin{propoap}
Si $\omega_i\in\Lambda_{r_i}(V)$, $i=1,\dots ,k$, entonces:
$$\omega_1\wedge\cdots\wedge\omega_k=\frac{(r_1+\cdots +r_k)!}{r_1!\dots r_k!}
Alt(\omega_1\otimes\cdots\otimes\omega _k).$$
\end{propoap}
\par\bigskip
Otras propiedades del Algebra Exterior son las siguientes:
\begin{propoap}
\begin{enumerate}
\item[(i)] Si $\omega ^1,\dots ,\omega^r\in\Lambda_1(V)$ y $\sigma\in{\cal S}
_r$, entonces:
$$\omega^1\wedge\cdots\wedge\omega^r=\varepsilon(\sigma)\omega^{
\sigma(1)}\wedge\cdots\wedge\omega^{\sigma(r)}.$$
\item[(ii)] Si $v_1,\dots ,v_r\in V$ y $\omega^1,\dots\omega^r\in
\Lambda_1(V)$, entonces:
$$(\omega^1\wedge\cdots\wedge\omega^r)(v_1,\dots ,v_r)={\rm det}(\omega^i(v_j))
.$$
\end{enumerate}
\end{propoap}
{\sc Demostración:} En primer lugar, para (i):
$$\omega^1\wedge\cdots\wedge\omega^r=-\omega^1\wedge\cdots\wedge\omega^{i-1}
\wedge\omega^{i+1}\wedge\omega^i\wedge\omega^{i+2}\wedge\cdots\wedge\omega^r.$$ \hs Por tanto,
$$\omega^1\wedge\cdots\wedge\omega^i\wedge\cdots\wedge\omega^j\wedge\cdots
\wedge\omega^r=-\omega^1\wedge\cdots\wedge\omega^j\wedge\cdots\wedge\omega^i \wedge\cdots\wedge\omega^r$$ y, como
toda permutación es producto de transposiciones, se tiene (i). Para (ii), se observa que:
$$(\omega^1\wedge\cdots\wedge\omega^r)(v_1,\dots ,v_r)=r!Alt(\omega^1\otimes
\cdots\otimes\omega^r)(v_1,\dots ,v_r)=$$
$$=r!\frac{1}{r!}\sum_{\sigma\in{\cal S}_r}\varepsilon(\sigma)\omega^1\otimes
\dots\otimes\omega^r(v_{\sigma (1)},\dots ,v_{\sigma(r)})=$$
$$=\sum_{\sigma\in{\cal S}_r}\varepsilon(\sigma)\omega^1(v_{\sigma (1)})\dots
\omega^r(v_{\sigma(r)})=det(\omega^i(v_j)).\eqno{\Box}$$
\begin{propoap}
Sea $\{e_1,\dots ,e_n\}$ una base de $V$ y $\{\theta^1,\dots ,\theta^n\}$ su base dual. Considérense $i_1,\dots
i_n$, enteros tales que $1\leq i_1<\cdots <i_r\leq n$. Entonces, los productos
$\theta^{i_1}\wedge\cdots\wedge\theta^{ i_r}$, cuando $i_1,\dots ,i_r$ se eligen de todas las formas posibles en
las condiciones anteriores, son una base de $\Lambda _r(V)$.
\end{propoap}
{\sc Demostración:} En primer lugar se probará que son generadores. Si $\omega \in\Lambda _r(V)$, entonces
$\omega\in T^0_r(V)$ y, por tanto,
$$\omega=\sum_{i_1,\dots ,i_r=1}^n\omega(e_{i_1},\dots ,e_{i_r})\theta^{i_1}
\otimes\cdots\otimes\theta^{i_r},$$ lo que implica que:
$$\omega=Alt(\omega)=\sum_{i_1,\dots ,i_r=1}^n\omega(e_{i_1},\dots ,e_{i_r})
Alt(\theta^{i_1}\otimes\cdots\otimes\theta^{i_r})=$$
$$=\frac{1}{r!}\sum_{i_1,\dots ,i_r=1}^n\omega(e_{i_1},\dots ,e_{i_r})\theta^
{i_1}\wedge\cdots\wedge\theta^{i_r}=$$
$$=\frac{1}{r!}\sum_{1\leq i_1<\cdots<i_r\leq n}a_{i_1\dots i_r}\theta^{i_1}
\wedge\cdots\wedge\theta ^{i_r}.$$ \hs Además, son independientes. En efecto, si
$$\sum_{1\leq i_1<\cdots<i_r\leq n}\lambda_{i_1\dots i_r}\theta^{i_1}
\wedge\cdots\wedge\theta ^{i_r}=0,$$ según la proposición anterior se tiene que
$$\theta^{i_1}\wedge\cdots\wedge\theta^{i_r}(e_{j_1},\dots,e_{j_r})=
\left \{
\begin{array}{ccc}
0 & {\rm si} & \{i_1,\dots ,i_r\}\neq\{j_1,\dots ,j_r\},\\
\varepsilon(\sigma) & {\rm si} & \{i_1,\dots ,i_r\}=\{j_1,\dots ,j_r\},
\end{array}
\right.$$ donde $\sigma$ es la permutación $i_k\mapsto j_k$, $k=1,\dots ,r$. Por tanto:
$$\lambda_{j_1 \dots j_r}=0,\forall j_1,\dots ,j_r/ 1\leq j_1<\cdots<
j_r\leq n.\eqno{\Box}$$

\newpage

\begin{coroap}
Sea $r\in\N$.
\begin{enumerate}
\item[(i)] Si $r>n$, entonces $\Lambda_r(V)=\{0\}$.
\item[(ii)] Si $r\leq n$, entonces $\dim (\Lambda_r(V))={n\choose r}$.
\end{enumerate}
\end{coroap}
{\sc Demostración:} Si $r>n$, todo elemento de la base es nulo, pues en todo producto de la forma
$\theta^{i_1}\wedge\cdots\wedge\theta^{i_r}$ hay elementos repetidos, con lo que el producto exterior es nulo. El
caso $r\leq n$ se deduce directamente de la proposición anterior (?`por qué?).\hfill$\Box$
\par
Como consecuencia del corolario anterior, tenemos que $\Lambda (V)$ es suma directa de un número
\underline{finito} de espacios vectoriales,
$$\Lambda(V)=\R\oplus V^*\oplus\Lambda_2(V)\oplus\cdots\oplus\Lambda_n(V),$$
lo que implica que:
$${\rm \dim}(\Lambda(V))={n\choose 0}+{n\choose 1}+\cdots+{n\choose n}=(1+1)^n
=2^n.$$

\end{document}