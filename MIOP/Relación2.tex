\documentclass[twoside]{article}
\usepackage{../estilo-ejercicios}

%--------------------------------------------------------
\begin{document}

\title{Modelos de Investigación Operativa\\ Relación 2}
\author{Rafael González López, Javier Aguilar Martín}
\date{}
\maketitle

\begin{ejercicio}{1}
Una persona busca sitio para aparcar cerca de su casa. Se aproxima desde el oeste y su objetivo es aparcar tan cerca como le sea posible. La posición de las plazas de aparcamiento aparece representada en la siguiente figura:
$$T\ T-1\ T-2\dots 3\ 2\ 1$$
Cuando va conduciendo solo puede apreciar si la plaza que está a su lado está libre u ocupada. Cada vez que está al lado de la plaza $t$ libre debe decidir si aparca (y camina los $4t$ metros desde la plaza hasta su casa) o por el contrario, sigue avanzando. Sabe que una vez que una plaza se deja atrás no se puede volver a por ella. 

Finalmente, si se pasa de su casa (situada junto a la plaza 0), deberá llevar su coche hasta $M$ metros.

Por su experiencia estima que la probabilidad de que la plaza $t$ esté libre es $p$ independientemente de las restantes. Se desea determinar la política óptima de aparcamiento que minimiza la distancia esperada recorrida por la persona a pie hasta su casa.
\begin{enumerate}
\item Formule el problema mediante programación dinámica.
\item Pruébese que si es óptimo no aparcar en la plaza $s$ libre tampoco lo es en las plazas $t$ con $t\geq s$.
\item Resuélvase para $T=100$, $M=40$ y $p=1/2$.
\end{enumerate}
\newpage
\begin{solucion}\
\begin{enumerate}

\item Etapas $\{1,\dots, T\}$, Etapas $(t,\alpha)$, siendo $t$ la plaza en la que nos encontramos y $\alpha$ la situación de la plaza ($\alpha=0$: ocupada; $\alpha=1$: libre). $f(t,\alpha)=$ mínima distancia esperada que recorrerá a pie hasta la casa si se encuentra en la plaza $t$ y esta está en estado $\alpha$. $f(1,0)=M$, $f(1,1)=\min\{4,M\}$. Supondremos que $M>4$ porque en caso contrario siempre sería preferible pasarse.

$$f(t,\alpha)=\begin{cases}
 pf(t-1,1)+(1-p)f(t-1,0)& \alpha=0\\
 \min\{4t,pf(t-1,1)+(1-p)f(t-1,0)\} & \alpha=1
\end{cases}$$

\item Consideremos que la plaza $s$ está libre y es óptimo no aparcar, entonces
$$f(s,1)=\min{\{4s,pf(s-1,1)+(1-p)f(s-1,0)\}}=\min{\{4s,f(s,0)\}}$$
Si lo óptimo es no aparcar a pesar de que la plaza esté libre entonces $f(s,1)=f(s,0)$, es decir, que $4s\geq f(s,0)$. Consideremos el caso sucesor. 
$$f(s+1,1)=\min\begin{cases}
4(s+1)\\
pf(s,1)+(1-p)f(s,0)=pf(s,1)+(1-p)f(s,1)=f(s,1)
\end{cases}$$
Como $4s\geq f(s,1)$, también $4(s+1)\geq f(s,1)$. Es claro que, por inducción, si $t\geq s$ entonces no será óptimo aparcar tampoco en la plaza $t$.

\item Veamos algunos cálculos
\begin{equation*}
  \begin{split}
    f(1,0)&=40\\
    f(1,1)&= 4\\
    f(2,0)&= \frac{1}{2}f(1,1)+\frac{1}{2}f(1,0)=22\\
    f(2,1)& = \min{\{8,22\}}= 8
  \end{split}
\quad\quad
  \begin{split}
    f(3,0)&=\frac{1}{2}f(2,1)+\frac{1}{2}f(2,0) = 15\\
    f(3,1)&=\min\{12,15\}=12\\
    f(4,0)& = \frac{1}{2}f(3,1)+\frac{1}{2}f(3,0)=13.5\\
    f(4,1)&= \min\{16,13.5\} = 13.5
  \end{split}
\end{equation*}
Como en el aparcamiento número $4$ no es óptimo aparcar, tampoco lo será en ningún otro desde el $4$ hasta el $100$. Es decir, la solución óptima es aparcar en cualquier plaza disponible después de la 4.


\end{enumerate}
\end{solucion}
\end{ejercicio}

\newpage 
\begin{ejercicio}{2}
Cada año al propietario de un coto de caza debe determinar el número de piezas que cazará. Durante el año $t$ el precio de una pieza es $p_t$. Si al comienzo del año $t$ el coto contiene $b$ piezas, la caza de $x$ piezas tiene un costo de $c(x/b)$. Durante el periodo de veda, que es al finalizar el periodo de caza, el número de piezas del coto se ve multiplicado por un factor $D$, con $P[D=d]=q(d)$. Determinar la estrategia de caza que maximiza el beneficio esperado obtenido por el propietario del coto.


\begin{solucion}
Etapas $\{1,\dots, T\}$, estados $(t,b)$ con etapa y número de piezas disponibles al principio del año.
$f(t,b)=$ máximo beneficio esperado obtenido por el propietario desde $t$ hasta $T$ con $b$ piezas al principio del año $t$.
$$f(T,b)=\max_{0\leq x\leq b}\{p_tx-c(x/b)\}$$
$$f(t,b)=\max_{0\leq x\leq b}\{p_tx-c(x/b)+\sum_d q(d)f(t+1,(b-x)d)\}$$
donde $d$ son los posibles valores de la variable $D$. 
\end{solucion}

\end{ejercicio}

\newpage 
\begin{ejercicio}{3}
Una compañía petrolítfera tiene $D$ u.m. para asignar en la perforación de pozos en $T$ lugares. Si se asignan $x$ u.m. al pozo $t$, existe una probabilidad $q_t(x)$ de encontrar petróleo. Si en la perforación del pozo $t$ se encuentra petróleo, la empresa obtiene una ganancia de $r_t$ u.m. Maximizar el valor esperado del petróleo encontrado en los pozo.
\begin{solucion}
Hay $T$ etapas, con estados $(t,c)$ formados por la etapa y las u.m. disponibles. $f(t,c):$ máximo beneficio esperado desde $t$ hasta $T$ si se dispone de $c$ u.m.  

$$f(t,c)=\max_{x\leq c}\{r_tq_t(x)+f(t+1,c-x)\}$$
$$f(T,c)=\max_{x\leq c}\{r_tq_t(x)\}$$

Si quisiéramos considerar que no es necesario invertir todo el dinero podemos considerar una etapa $T+1$ con $f(T+1,c)=c$ y en la etapa $T$ maximizar $r_tq_t(c-x)$. 







\end{solucion}
\end{ejercicio}	


\newpage 
\begin{ejercicio}{4}
En un juego se puede apostar cualquier cantidad y se gana esa misma cantidad con probabilidad $2/3$. Se pierde la cantidad apostada con probabilidad $1/3$.

Se desea determinar, partiendo de 3 u.m., la política óptima acerca del número de fichas a apostar en tres jugadas consecutivas de forma que la probabilidad de tener al menos cinco u.m. al final sea máxima. La decisión en cada jugada debe tener en cuenta los resultados de las jugadas anteriores.
\begin{solucion}
Etapas $\{1,2,3,4\}$, añadimos una etapa adicional. Estados $(t,c)=($etapa, fichas disponibles$)$. $f(t,c)=$ máxima probabilidad de acabar con al menos 5 fichas desde la etapa t si se dispone de c fichas.  
$$f(4,c)=\begin{cases}
1 & c\geq 5\\
0 & c\leq 4
\end{cases}$$
$$f(t,c)=\maxi{0\leq x\leq c}{\frac{2}{3}f(t+1,c+x)+\frac{1}{3}f(t+1,c-x)}$$
Si hacemos algunos cálculos tenemos que
\begin{equation*}
  \begin{split}
f(3,c)=\left\{\begin{array}{lll}
1 & c\geq 5 & x_3 \in [0,c-5]\\
\frac{2}{3} & 3\leq c\leq 4 & x_3 \in [2,c]\\
0 & c\leq 2 & x_3 \in [0,c]
\end{array}\right.
  \end{split}
\quad\quad
  \begin{split}
f(2,c)=\left\{\begin{array}{lll}
1 & c\geq 5 & x_2 \in [0,c-5]\\
\frac{8}{9} & c=4 & x_2 =1\\
\frac{2}{3}& c = 3 & x_2 =0,2,3\\
\frac{4}{9}& c = 2 & x_2 = 1,2\\
0 & c\leq 1 & x_2\in [0,c]
\end{array}\right.
  \end{split}
\end{equation*} 
$f(1,3)=\maxi{}{\frac{2}{3},\frac{20}{27},\frac{2}{3},\frac{2}{3}}=\frac{20}{27}$. Por tanto, la estrategia óptima es $x_1=1$, si ganas, $x_2=1$ y $x_3=0$. Si pierdes la segunda, $x_3 = 2,3$. Si pierdes la primera, $x_2=1,2$ y, si ganas esta, $x_3 = 2,3$ o $4$ si tomaste $x_2=2$. Si también pierdes la segunda no hay nada que hacer.
\end{solucion}
\end{ejercicio}

\newpage 
\begin{ejercicio}{5}
Un jugador puede apostar cualquier fracción de su fortuna en un juego de azar. En cada partida recibe un múltiplo de $\gamma>1$ de la cantidad apostada con probabilidad $p$ y pierde la cantidad apostada con probabilidad $q=1-p$, donde $p\gamma>1$. El jugador parte con un capital $C$, puede jugar a lo sumo $N$ partidas y desea determinar la estrategia de apuestas que maximice la esperanza del logaritmo de su capital tras las $N$ partidas.
\begin{enumerate}
\item Formular el problema utilizando la programación dinámica.
\item Pruébese que la estrategia óptima consiste en apostar en cada etapa una fracción $\alpha^*$ de su capital, donde
$$\alpha^*=\frac{p(\gamma-1)-q}{\gamma-1}.$$
Esta estrategia del juego se conoce como estrategia de Kelly.
\end{enumerate}
\begin{solucion}
Etapas $\{1,\dots, N\}$ y añadimos una etapa $N+1$ para modelar el logaritmo.
Estados $(t,c)$ etapa,cantidad disponible. 
$f(t,c)=$máxima esperanza del logaritmo del capital desde $t$ hasta el final si disponemos de $c$ unidades.
$$f(N+1,c)=\begin{cases}
\log{c} & c>0\\
0 & cc
\end{cases}$$
$$f(t,c)=\max_{0\leq x\leq c}\{pf(t+1,c+x(\gamma-1))+qf(t+1,c-x)\}$$ 

$f(N,c)=\max p\log(c+x(\gamma-1))+q\log(c-x)$. Calculamos su máximo igualando la derivada a 0 y obtenemos $x=\frac{1-p\gamma}{1-\gamma}=\frac{p(\gamma-1)-1}{\gamma-1}c=\alpha^* c$, que sustituyendo nos da que $f(N,c)=\log((1+\alpha^*)(\gamma-1)^p(1-\alpha^*)^qc^pc^q)=\log(k^*c)$. Vamos a suponer que $f(t+1,x)=\log(k^*x)$ y veamos que también es cierto para $t$.

Sustituyendo en la expresión anterior los valores correspondientes obtenemos
$$f(t,c)=\max_{0\leq x\leq c}\{p\log(k^*(c+x(\gamma-1)))+q\log(k^*(c-x))$$
derivando e igualando a 0 deducimos que esta función alcanza su máximo en $x=\alpha^*c$, al igual que antes, luego hemos probado lo que queríamos.
\end{solucion}
\end{ejercicio}

\newpage 
\begin{ejercicio}{6}\label{6}
Un jugador va a participar en tres juegos consecutivos. En cada juego, puede apostar lo que gana; la cantidad apostada puede ascender a cualquier cantidad entre cero y la cantidad de dinero que le quede después de las apuestas en los juegos anteriores. En cada encuentro, la probabilidad de que gane el juego y, por lo tanto, la apuesta, es $1/2$. Si no gana, pierde la apuesta. Comenzará con 75 u.m. y su meta es tener 100 u.m. al finalizar los tres juegos (exactamente 100). El jugador desea determinar su política óptima de apuesta (incluyendo todos los empates) que maximice la probabilidad de tener exactamente 100 u.m. después de los tres juegos.
\end{ejercicio}
\begin{solucion}
Etapas $\{1,2,3,4\}$. Estados $(t,c)$: etapa, cantidad disponible.
$f(t,c)=$ máxima probabilidad de obtener 100 u.m. desde $t$ hasta que termine el juego.
$$f(4,c)=\begin{cases}
1 & c=100\\
0 & cc
\end{cases}$$
$$f(t,c)= \frac{1}{2}\maxi{0\leq x\leq c}{f(t+1,c+x)+f(t+1,c-x)}$$
\begin{center}
\begin{tabular}{c|cccccc}
		& $<50$	& 50 	& 51 & $\cdots$	& 99 & 100\\
\hline
$f(3,c)$  & 0 			& $1/2$ 	& $1/2$ &$\cdots$& $1/2$ &  1\\
$x_3$     &   			& 50 	& 49 &	$\cdots$ & $1$  &  0\\ 
\end{tabular}
\end{center}

%\begin{equation*}
\begin{tabular}{c|ccccccccccccc}
		& $<25$	& 25 	& 26 & 		$\cdots$ & 49	& 50 & $\cdots$ & 74 & 75 & $\cdots$ & 99 & 100\\
\hline
$f(2,c)$  & 0 & $1/4$	& $1/4$ & $\cdots$& $1/4$ & $1/2$ &$\cdots$& $1/2$ & $3/4$ &$\cdots$  & $3/4$ &1\\
$x_2$     &  & 25 & 24 &	$\cdots$ & 0 & 50   & $\cdots$  &$26$ & $25$ & $\cdots$ & $1$ &0\\ 
\end{tabular}
%\end{equation*}

Finalmente, calculamos $f(1,75)=\dfrac{1}{2}\maxi{0\leq x\leq 75}{f(2,75+x)+f(2,75-x)}=3/4$. Si $x=0$ o $x=25$. 
\end{solucion}

\newpage 
\begin{ejercicio}{7}
Imagine que se tienen 5000 u.m. para invertir y que tendrá la oportunidad de hacerlo en cualquiera de dos inversiones A o B al principio de cada uno de los próximos tres años. Existe incertidumbre respecto al rendimiento de ambas inversiones. Si se invierten en A, se puede perder todo el dinero o (con probabilidad más alta) obtener 10000 u.m. (una ganancia de 5000 u.m. al final del año). Las probabilidades para estos eventos son:
\begin{center}
\begin{tabular}{c| c c}
\hline
Inversión & Rendimiento & Probabilidad\\
\hline
A & 0 & 0.3\\
  & 10000 &  0.7\\
 \hline
 B & 5000 & 0.9\\
   & 10000 & 0.1\\
   \hline
\end{tabular}
\end{center}
Se puede hacer (a lo sumo) una inversión al año y solo se puede invertir 5000 u.m. cada vez.
\begin{enumerate}
\item Utilice programación dinámica para encontrar la política de inversión que maximice la cantidad de dinero esperada que se tendrá después de los tres años.
\item Utilice programación dinámica para encontrar la política óptima de inversión que maximice la probabilidad de tener por lo menos 10000 u.m. después de tres años.
\end{enumerate}
\end{ejercicio}
\begin{solucion}
\begin{enumerate}
\item[]
\item 3 etapas, estados $(t,c)$ de etapa y cantidad disponible. $f(t,c)$ es la máxima ganancia esperada desde el año $t$ hasta el final si disponemos de $c$ u.m..
$$f(t,c)=\begin{cases}
\max\begin{cases}
0'3f(t+1,c-5000)+0'7f(t+1,c+5000)\\
0'9f(t+1,c)+0'1f(t+1,c+5000)
\end{cases}& c\geq 5000\\
0 & c<5000
\end{cases}
$$
Dado que $\maxi{}{0'3\cdot 0+0'7\cdot 10000, 0'9\cdot 5000+0'1\cdot 10000} = 7000$, que se da para la inversión $A$, podemos decir que
$$f(3,c) = 
\begin{cases}
2000+c & c\geq 5000\\
0 & c<5000
\end{cases}
$$

Por tanto $x_3=A$. 

En la etapa 2 se pueden dar los siguientes casos:
\begin{align*}
f(2,0)&=0\\
f(2,5000)&=\max\{0'3f(3,0)+0'7f(3,10000),0'9f(3,5000)+0'1f(3,10000)\}\\
&=\max\{8400,7500\}=8400(A)\\
f(2,10000)&=\max\{0'3f(3,5000)+0'7f(3,15000),0'9f(3,10000)+0'1f(3,15000)\}\\
&=\max\{14000,12500\}=14000(A)
\end{align*}
 

En la etapa 1 solo puede ocurrir lo siguiente:

$$f(1,5000)=\max\begin{cases}
0'3f(2,0)+0'7f(2,10000)=\boxed{9800}(A)\\
0'9f(2,5000)+0'1f(2,10000)=8961
\end{cases}$$

Por tanto la decisión óptima en todos los casos es A. 

\item Añadimos una etapa adicional para modelar la probabilidad. $f(4,c):$ máxima probabilidad de acabar después de los 3 años con 10000 u.m. o más desde la etapa $t$ si se dispone de c u.m.  
$$f(4,c)=\begin{cases}
1 & c\geq 10000\\
0 & c<10000
\end{cases}$$
$$f(t,c)=\max\begin{cases}
0'3f(t+1,c-5000)+0'7f(t+1,c+5000) & x_t=A\\
0'9f(t+1,c)+0'1f(t+1,c+5000) & x_t=B
\end{cases}$$

Vamos a la etapa 3. 
\begin{align*}
f(3,0)&=0\\
f(3,5000)&=\max\begin{cases}
0'3f(4,0)+0'7f(4,10000)=0'7 & x_3=A\\
0'9f(4,5000)+0'1f(4,10000)=0'1 & x_3=B
\end{cases} = 0'7(A)\\
f(3,10000)&=\max\begin{cases}
0'3f(4,5000)+0'7f(4,15000)=0'7 & x_3=A\\
0'9f(4,10000)+0'1f(4,15000)=1 & x_3=B
\end{cases} = 1(B)\\
f(3,15000) &= 1(A||B)
\end{align*}
Ahora la etapa 2: 
\begin{align*}
f(2,0)&=0\\
f(2,5000)&=\max\begin{cases}
0'3f(3,0)+0'7f(3,10000)=0'7 & x_2=A\\
0'9f(3,5000)+0'1f(3,10000)=0'73 & x_2=B
\end{cases}=0'73(B)\\
f(2,10000)&=\max\begin{cases}
0'3f(3,5000)+0'7f(3,15000)=0'7 & x_2=A\\
0'9f(3,10000)+0'1f(3,15000)=1 & x_2=B
\end{cases} = 1(B)
\end{align*}
Por último la etapa 1:
$$f(1,5000)=\max\begin{cases}
0'3f(2,0)+0'7f(2,10000)=0'7 & x_1=A\\
0'9f(2,5000)+0'1f(2,10000)=0'757 & x_1=B
\end{cases} = 0.757(B)$$

La máxima probabilidad de acabar con al menos 10000 u.m. es por tanto $0'757$, cuya estrategia óptima es invertir siempre en B.
\end{enumerate}
\end{solucion}


\newpage
\begin{ejercicio}{8} 
Cuando un jugador de tenis sirve, tiene dos oportunidades para que la pelota caiga dentro de los límites. Si falla dos veces, pierde un punto (1 unidad). Si intenta un ace, tiene una probabilidad de $3/8$ de que caiga dentro del cuadro. Si saca un servicio suave, su probabilidad de hacerlo bien es $7/8$. Si el intento de ace cae dentro del cuadro, gana el punto (1 unidad) con probabilidad $2/3$, Con el servicio suave dentro del cuadro, la probabilidad de que gane el punto es $1/3$. Determinar la estrategia óptima.
\end{ejercicio}
\begin{solucion}
Las etapas son los dos servicios y los estados solo dependen de en qué servicio estemos. $f(t)$ es la máxima probabilidad de ganar el punto desde $t$. 
$$f(II)=
\maxi{}{\frac{3}{8}\frac{2}{3} (Ace),\frac{1}{3}\frac{7}{8}(Suave)}=\frac{7}{24}(Suave)
$$

$$f(I)=\max\begin{cases}
\dfrac{3}{8}\dfrac{2}{3}+f(II)\left(1-\dfrac{3}{8}\right) & Ace\\
\dfrac{7}{8}\dfrac{1}{3}+f(II)\left(1-\dfrac{2}{3}\right) & Suave
\end{cases}=\max\{0'432,0'328\}=0'4324$$ que corresponde a intentar un ace en el primero y en caso de fallar, sacar suave en el segundo.
\end{solucion}


\newpage

\begin{ejercicio}{extra}
Aplicar un procedimiento de programación dinámica para resolver el problema:
\begin{align*}
\min\sum_{i=1}^N (x_i-bx_i)^2\\
s.a. \sum_{i=1}^N x_i=C\\
x\geq 0
\end{align*}
\end{ejercicio}
\begin{solucion}
Obsérvese en primer lugar que $$\sum_{i=1}^N (x_i-bx_i)^2=\sum_{i=1}^N (1-b)^2x_i^2=(1-b)^2\sum_{i=1}^N x_i^2,$$ por lo que basta minimizar la suma de los cuadrados con las restricciones anteriores. Vamos a identificar $N$ etapas, cada una correspondiente al valor asignado a la variable $x_i$. Definimos los estados $(i,d)$, donde $i$ es el índice de la variable en la que nos encontramos y $d=C-\sum_{j=1}^i x_j$ es la cantidad que queda disponible para asignar a la variable. En nuestro modelo, $f(i,d)$ representará el valor mínimo de $\sum_{j=i}^N x_i^2$ si en la etapa $i$ hay una cantidad $d$ para asignar. La función recursiva será $f(i,d)=\min_{0\leq x_i\leq d}  x_i^2+f(i+1,d-x_i)$, teniendo en cuenta que $f(N,d)=\begin{cases}
C^2 & d\geq C\\
d^2 & C\geq d\geq 0\\
+\infty & d<0
\end{cases}$. 

Vamos a probar por inducción que $f(N-i,d)=\frac{d^2}{i+1}$, alcanzando dicho valor en $x_i=\frac{d}{i+1}$, $\forall i=0,\dots, N-1$ y $0\leq d\leq C$. Tenemos como caso inicial que $f(N-0,d)=\frac{d^2}{0+1}$, valor alcanzado en $x_N=\frac{d}{0+1}$. Supongamos como hipótesis de inducción que

$$f(N-i,d)=\min_{0\leq x_{N-i}\leq d}x_{N-i}^2+(d-x_{N-i})^2$$
obtiene su mínimo en $x_{N-i}=\frac{d}{i+1}$, donde vale $\frac{d^2}{i+1}$. Entonces

$$f(N-(i+1),d)=\min_{0\leq x_{N-(i+1)}\leq C}x_{N-(i+1)}^2+\frac{(d-x_{N-(i+1)})^2}{i+1}$$
La función es una parábola que alcanza su mínimo en $x_{N-(i+1)}=\frac{d}{i+2}$, donde vale $\frac{d^2}{i+2}$, lo que prueba nuestra tesis.

Como la solución es $f(1,C)$ basta sutituir estos valores y obtenemos $f(1,C)=\frac{C^2}{N}$, para $x_1=\frac{C}{N}$. Para recuperar los demás $x_i$ probaremos por inducción que $x_i=\frac{C}{N}\ \forall i=1,\dots,N$. El caso inicial es el que acabamos de calcular. Fijemos $2\leq j\leq N$ y supongamos entonces que $x_i=\frac{C}{N}\ \forall i=1,\dots,j-1$. Tenemos que $j=N-(N-j)$ y que queda una cantidad $d=C-\sum_{i=1}^{j-1}\frac{C}{N}=\frac{N-j+1}{N}C$. Por tanto sustituimos en la fórmula obtenida en la anterior inducción y resulta
$$x_j=\frac{\frac{N-j+1}{N}C}{N-j+1}=\frac{C}{N}$$
como queríamos demostrar.
\end{solucion}


\end{document}